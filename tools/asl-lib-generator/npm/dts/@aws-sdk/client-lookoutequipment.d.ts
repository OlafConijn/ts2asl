// Generated by dts-bundle v0.7.3
// Dependencies for this module:
//   @aws-sdk/types
//   @aws-sdk/smithy-client
//   @aws-sdk/config-resolver
//   @aws-sdk/middleware-host-header
//   @aws-sdk/middleware-retry
//   @aws-sdk/middleware-signing
//   @aws-sdk/middleware-user-agent
//   @aws-sdk/protocol-http

declare module '@aws-sdk/client-lookoutequipment' {
    import { HttpHandlerOptions as __HttpHandlerOptions } from "@aws-sdk/types";
    import { CreateDatasetCommandInput, CreateDatasetCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/CreateDatasetCommand";
    import { CreateInferenceSchedulerCommandInput, CreateInferenceSchedulerCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/CreateInferenceSchedulerCommand";
    import { CreateModelCommandInput, CreateModelCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/CreateModelCommand";
    import { DeleteDatasetCommandInput, DeleteDatasetCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DeleteDatasetCommand";
    import { DeleteInferenceSchedulerCommandInput, DeleteInferenceSchedulerCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DeleteInferenceSchedulerCommand";
    import { DeleteModelCommandInput, DeleteModelCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DeleteModelCommand";
    import { DescribeDataIngestionJobCommandInput, DescribeDataIngestionJobCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DescribeDataIngestionJobCommand";
    import { DescribeDatasetCommandInput, DescribeDatasetCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DescribeDatasetCommand";
    import { DescribeInferenceSchedulerCommandInput, DescribeInferenceSchedulerCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DescribeInferenceSchedulerCommand";
    import { DescribeModelCommandInput, DescribeModelCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DescribeModelCommand";
    import { ListDataIngestionJobsCommandInput, ListDataIngestionJobsCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListDataIngestionJobsCommand";
    import { ListDatasetsCommandInput, ListDatasetsCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListDatasetsCommand";
    import { ListInferenceEventsCommandInput, ListInferenceEventsCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListInferenceEventsCommand";
    import { ListInferenceExecutionsCommandInput, ListInferenceExecutionsCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListInferenceExecutionsCommand";
    import { ListInferenceSchedulersCommandInput, ListInferenceSchedulersCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListInferenceSchedulersCommand";
    import { ListModelsCommandInput, ListModelsCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListModelsCommand";
    import { ListSensorStatisticsCommandInput, ListSensorStatisticsCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListSensorStatisticsCommand";
    import { ListTagsForResourceCommandInput, ListTagsForResourceCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListTagsForResourceCommand";
    import { StartDataIngestionJobCommandInput, StartDataIngestionJobCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/StartDataIngestionJobCommand";
    import { StartInferenceSchedulerCommandInput, StartInferenceSchedulerCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/StartInferenceSchedulerCommand";
    import { StopInferenceSchedulerCommandInput, StopInferenceSchedulerCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/StopInferenceSchedulerCommand";
    import { TagResourceCommandInput, TagResourceCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/TagResourceCommand";
    import { UntagResourceCommandInput, UntagResourceCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/UntagResourceCommand";
    import { UpdateInferenceSchedulerCommandInput, UpdateInferenceSchedulerCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/UpdateInferenceSchedulerCommand";
    import { LookoutEquipmentClient } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    /**
        * <p>Amazon Lookout for Equipment is a machine learning service that uses advanced analytics
        *          to identify anomalies in machines from sensor data for use in predictive maintenance.
        *       </p>
        */
    export class LookoutEquipment extends LookoutEquipmentClient {
            /**
                * <p>Creates a container for a collection of data being ingested for analysis. The dataset
                *          contains the metadata describing where the data is and what the data actually looks like.
                *          In other words, it contains the location of the data source, the data schema, and other
                *          information. A dataset also contains any tags associated with the ingested data. </p>
                */
            createDataset(args: CreateDatasetCommandInput, options?: __HttpHandlerOptions): Promise<CreateDatasetCommandOutput>;
            createDataset(args: CreateDatasetCommandInput, cb: (err: any, data?: CreateDatasetCommandOutput) => void): void;
            createDataset(args: CreateDatasetCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: CreateDatasetCommandOutput) => void): void;
            /**
                * <p> Creates a scheduled inference. Scheduling an inference is setting up a continuous
                *          real-time inference plan to analyze new measurement data. When setting up the schedule, you
                *          provide an S3 bucket location for the input data, assign it a delimiter between separate
                *          entries in the data, set an offset delay if desired, and set the frequency of inferencing.
                *          You must also provide an S3 bucket location for the output data. </p>
                */
            createInferenceScheduler(args: CreateInferenceSchedulerCommandInput, options?: __HttpHandlerOptions): Promise<CreateInferenceSchedulerCommandOutput>;
            createInferenceScheduler(args: CreateInferenceSchedulerCommandInput, cb: (err: any, data?: CreateInferenceSchedulerCommandOutput) => void): void;
            createInferenceScheduler(args: CreateInferenceSchedulerCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: CreateInferenceSchedulerCommandOutput) => void): void;
            /**
                * <p>Creates an ML model for data inference. </p>
                *          <p>A machine-learning (ML) model is a mathematical model that finds patterns in your data.
                *          In Amazon Lookout for Equipment, the model learns the patterns of normal behavior and
                *          detects abnormal behavior that could be potential equipment failure (or maintenance
                *          events). The models are made by analyzing normal data and abnormalities in machine behavior
                *          that have already occurred.</p>
                *          <p>Your model is trained using a portion of the data from your dataset and uses that data
                *          to learn patterns of normal behavior and abnormal patterns that lead to equipment failure.
                *          Another portion of the data is used to evaluate the model's accuracy. </p>
                */
            createModel(args: CreateModelCommandInput, options?: __HttpHandlerOptions): Promise<CreateModelCommandOutput>;
            createModel(args: CreateModelCommandInput, cb: (err: any, data?: CreateModelCommandOutput) => void): void;
            createModel(args: CreateModelCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: CreateModelCommandOutput) => void): void;
            /**
                * <p> Deletes a dataset and associated artifacts. The operation will check to see if any
                *          inference scheduler or data ingestion job is currently using the dataset, and if there
                *          isn't, the dataset, its metadata, and any associated data stored in S3 will be deleted.
                *          This does not affect any models that used this dataset for training and evaluation, but
                *          does prevent it from being used in the future. </p>
                */
            deleteDataset(args: DeleteDatasetCommandInput, options?: __HttpHandlerOptions): Promise<DeleteDatasetCommandOutput>;
            deleteDataset(args: DeleteDatasetCommandInput, cb: (err: any, data?: DeleteDatasetCommandOutput) => void): void;
            deleteDataset(args: DeleteDatasetCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: DeleteDatasetCommandOutput) => void): void;
            /**
                * <p>Deletes an inference scheduler that has been set up. Already processed output results
                *          are not affected. </p>
                */
            deleteInferenceScheduler(args: DeleteInferenceSchedulerCommandInput, options?: __HttpHandlerOptions): Promise<DeleteInferenceSchedulerCommandOutput>;
            deleteInferenceScheduler(args: DeleteInferenceSchedulerCommandInput, cb: (err: any, data?: DeleteInferenceSchedulerCommandOutput) => void): void;
            deleteInferenceScheduler(args: DeleteInferenceSchedulerCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: DeleteInferenceSchedulerCommandOutput) => void): void;
            /**
                * <p>Deletes an ML model currently available for Amazon Lookout for Equipment. This will
                *          prevent it from being used with an inference scheduler, even one that is already set up.
                *       </p>
                */
            deleteModel(args: DeleteModelCommandInput, options?: __HttpHandlerOptions): Promise<DeleteModelCommandOutput>;
            deleteModel(args: DeleteModelCommandInput, cb: (err: any, data?: DeleteModelCommandOutput) => void): void;
            deleteModel(args: DeleteModelCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: DeleteModelCommandOutput) => void): void;
            /**
                * <p>Provides information on a specific data ingestion job such as creation time, dataset
                *          ARN, and status.</p>
                */
            describeDataIngestionJob(args: DescribeDataIngestionJobCommandInput, options?: __HttpHandlerOptions): Promise<DescribeDataIngestionJobCommandOutput>;
            describeDataIngestionJob(args: DescribeDataIngestionJobCommandInput, cb: (err: any, data?: DescribeDataIngestionJobCommandOutput) => void): void;
            describeDataIngestionJob(args: DescribeDataIngestionJobCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: DescribeDataIngestionJobCommandOutput) => void): void;
            /**
                * <p>Provides a JSON description of the data in each time series dataset, including names,
                *          column names, and data types.</p>
                */
            describeDataset(args: DescribeDatasetCommandInput, options?: __HttpHandlerOptions): Promise<DescribeDatasetCommandOutput>;
            describeDataset(args: DescribeDatasetCommandInput, cb: (err: any, data?: DescribeDatasetCommandOutput) => void): void;
            describeDataset(args: DescribeDatasetCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: DescribeDatasetCommandOutput) => void): void;
            /**
                * <p> Specifies information about the inference scheduler being used, including name, model,
                *          status, and associated metadata </p>
                */
            describeInferenceScheduler(args: DescribeInferenceSchedulerCommandInput, options?: __HttpHandlerOptions): Promise<DescribeInferenceSchedulerCommandOutput>;
            describeInferenceScheduler(args: DescribeInferenceSchedulerCommandInput, cb: (err: any, data?: DescribeInferenceSchedulerCommandOutput) => void): void;
            describeInferenceScheduler(args: DescribeInferenceSchedulerCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: DescribeInferenceSchedulerCommandOutput) => void): void;
            /**
                * <p>Provides a JSON containing the overall information about a specific ML model, including
                *          model name and ARN, dataset, training and evaluation information, status, and so on.
                *       </p>
                */
            describeModel(args: DescribeModelCommandInput, options?: __HttpHandlerOptions): Promise<DescribeModelCommandOutput>;
            describeModel(args: DescribeModelCommandInput, cb: (err: any, data?: DescribeModelCommandOutput) => void): void;
            describeModel(args: DescribeModelCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: DescribeModelCommandOutput) => void): void;
            /**
                * <p>Provides a list of all data ingestion jobs, including dataset name and ARN, S3 location
                *          of the input data, status, and so on. </p>
                */
            listDataIngestionJobs(args: ListDataIngestionJobsCommandInput, options?: __HttpHandlerOptions): Promise<ListDataIngestionJobsCommandOutput>;
            listDataIngestionJobs(args: ListDataIngestionJobsCommandInput, cb: (err: any, data?: ListDataIngestionJobsCommandOutput) => void): void;
            listDataIngestionJobs(args: ListDataIngestionJobsCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: ListDataIngestionJobsCommandOutput) => void): void;
            /**
                * <p>Lists all datasets currently available in your account, filtering on the dataset name.
                *       </p>
                */
            listDatasets(args: ListDatasetsCommandInput, options?: __HttpHandlerOptions): Promise<ListDatasetsCommandOutput>;
            listDatasets(args: ListDatasetsCommandInput, cb: (err: any, data?: ListDatasetsCommandOutput) => void): void;
            listDatasets(args: ListDatasetsCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: ListDatasetsCommandOutput) => void): void;
            /**
                * <p> Lists all inference events that have been found for the specified inference
                *          scheduler. </p>
                */
            listInferenceEvents(args: ListInferenceEventsCommandInput, options?: __HttpHandlerOptions): Promise<ListInferenceEventsCommandOutput>;
            listInferenceEvents(args: ListInferenceEventsCommandInput, cb: (err: any, data?: ListInferenceEventsCommandOutput) => void): void;
            listInferenceEvents(args: ListInferenceEventsCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: ListInferenceEventsCommandOutput) => void): void;
            /**
                * <p> Lists all inference executions that have been performed by the specified inference
                *          scheduler. </p>
                */
            listInferenceExecutions(args: ListInferenceExecutionsCommandInput, options?: __HttpHandlerOptions): Promise<ListInferenceExecutionsCommandOutput>;
            listInferenceExecutions(args: ListInferenceExecutionsCommandInput, cb: (err: any, data?: ListInferenceExecutionsCommandOutput) => void): void;
            listInferenceExecutions(args: ListInferenceExecutionsCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: ListInferenceExecutionsCommandOutput) => void): void;
            /**
                * <p>Retrieves a list of all inference schedulers currently available for your account.
                *       </p>
                */
            listInferenceSchedulers(args: ListInferenceSchedulersCommandInput, options?: __HttpHandlerOptions): Promise<ListInferenceSchedulersCommandOutput>;
            listInferenceSchedulers(args: ListInferenceSchedulersCommandInput, cb: (err: any, data?: ListInferenceSchedulersCommandOutput) => void): void;
            listInferenceSchedulers(args: ListInferenceSchedulersCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: ListInferenceSchedulersCommandOutput) => void): void;
            /**
                * <p>Generates a list of all models in the account, including model name and ARN, dataset,
                *          and status. </p>
                */
            listModels(args: ListModelsCommandInput, options?: __HttpHandlerOptions): Promise<ListModelsCommandOutput>;
            listModels(args: ListModelsCommandInput, cb: (err: any, data?: ListModelsCommandOutput) => void): void;
            listModels(args: ListModelsCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: ListModelsCommandOutput) => void): void;
            /**
                * <p> Lists statistics about the data collected for each of the sensors that have been
                *          successfully ingested in the particular dataset. Can also be used to retreive Sensor
                *          Statistics for a previous ingestion job. </p>
                */
            listSensorStatistics(args: ListSensorStatisticsCommandInput, options?: __HttpHandlerOptions): Promise<ListSensorStatisticsCommandOutput>;
            listSensorStatistics(args: ListSensorStatisticsCommandInput, cb: (err: any, data?: ListSensorStatisticsCommandOutput) => void): void;
            listSensorStatistics(args: ListSensorStatisticsCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: ListSensorStatisticsCommandOutput) => void): void;
            /**
                * <p>Lists all the tags for a specified resource, including key and value. </p>
                */
            listTagsForResource(args: ListTagsForResourceCommandInput, options?: __HttpHandlerOptions): Promise<ListTagsForResourceCommandOutput>;
            listTagsForResource(args: ListTagsForResourceCommandInput, cb: (err: any, data?: ListTagsForResourceCommandOutput) => void): void;
            listTagsForResource(args: ListTagsForResourceCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: ListTagsForResourceCommandOutput) => void): void;
            /**
                * <p>Starts a data ingestion job. Amazon Lookout for Equipment returns the job status.
                *       </p>
                */
            startDataIngestionJob(args: StartDataIngestionJobCommandInput, options?: __HttpHandlerOptions): Promise<StartDataIngestionJobCommandOutput>;
            startDataIngestionJob(args: StartDataIngestionJobCommandInput, cb: (err: any, data?: StartDataIngestionJobCommandOutput) => void): void;
            startDataIngestionJob(args: StartDataIngestionJobCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: StartDataIngestionJobCommandOutput) => void): void;
            /**
                * <p>Starts an inference scheduler. </p>
                */
            startInferenceScheduler(args: StartInferenceSchedulerCommandInput, options?: __HttpHandlerOptions): Promise<StartInferenceSchedulerCommandOutput>;
            startInferenceScheduler(args: StartInferenceSchedulerCommandInput, cb: (err: any, data?: StartInferenceSchedulerCommandOutput) => void): void;
            startInferenceScheduler(args: StartInferenceSchedulerCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: StartInferenceSchedulerCommandOutput) => void): void;
            /**
                * <p>Stops an inference scheduler. </p>
                */
            stopInferenceScheduler(args: StopInferenceSchedulerCommandInput, options?: __HttpHandlerOptions): Promise<StopInferenceSchedulerCommandOutput>;
            stopInferenceScheduler(args: StopInferenceSchedulerCommandInput, cb: (err: any, data?: StopInferenceSchedulerCommandOutput) => void): void;
            stopInferenceScheduler(args: StopInferenceSchedulerCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: StopInferenceSchedulerCommandOutput) => void): void;
            /**
                * <p>Associates a given tag to a resource in your account. A tag is a key-value pair which
                *          can be added to an Amazon Lookout for Equipment resource as metadata. Tags can be used for
                *          organizing your resources as well as helping you to search and filter by tag. Multiple tags
                *          can be added to a resource, either when you create it, or later. Up to 50 tags can be
                *          associated with each resource. </p>
                */
            tagResource(args: TagResourceCommandInput, options?: __HttpHandlerOptions): Promise<TagResourceCommandOutput>;
            tagResource(args: TagResourceCommandInput, cb: (err: any, data?: TagResourceCommandOutput) => void): void;
            tagResource(args: TagResourceCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: TagResourceCommandOutput) => void): void;
            /**
                * <p>Removes a specific tag from a given resource. The tag is specified by its key. </p>
                */
            untagResource(args: UntagResourceCommandInput, options?: __HttpHandlerOptions): Promise<UntagResourceCommandOutput>;
            untagResource(args: UntagResourceCommandInput, cb: (err: any, data?: UntagResourceCommandOutput) => void): void;
            untagResource(args: UntagResourceCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: UntagResourceCommandOutput) => void): void;
            /**
                * <p>Updates an inference scheduler. </p>
                */
            updateInferenceScheduler(args: UpdateInferenceSchedulerCommandInput, options?: __HttpHandlerOptions): Promise<UpdateInferenceSchedulerCommandOutput>;
            updateInferenceScheduler(args: UpdateInferenceSchedulerCommandInput, cb: (err: any, data?: UpdateInferenceSchedulerCommandOutput) => void): void;
            updateInferenceScheduler(args: UpdateInferenceSchedulerCommandInput, options: __HttpHandlerOptions, cb: (err: any, data?: UpdateInferenceSchedulerCommandOutput) => void): void;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/CreateDatasetCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { CreateDatasetRequest, CreateDatasetResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface CreateDatasetCommandInput extends CreateDatasetRequest {
    }
    export interface CreateDatasetCommandOutput extends CreateDatasetResponse, __MetadataBearer {
    }
    /**
        * <p>Creates a container for a collection of data being ingested for analysis. The dataset
        *          contains the metadata describing where the data is and what the data actually looks like.
        *          In other words, it contains the location of the data source, the data schema, and other
        *          information. A dataset also contains any tags associated with the ingested data. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, CreateDatasetCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, CreateDatasetCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new CreateDatasetCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link CreateDatasetCommandInput} for command's `input` shape.
        * @see {@link CreateDatasetCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class CreateDatasetCommand extends $Command<CreateDatasetCommandInput, CreateDatasetCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: CreateDatasetCommandInput;
            constructor(input: CreateDatasetCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<CreateDatasetCommandInput, CreateDatasetCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/CreateInferenceSchedulerCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { CreateInferenceSchedulerRequest, CreateInferenceSchedulerResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface CreateInferenceSchedulerCommandInput extends CreateInferenceSchedulerRequest {
    }
    export interface CreateInferenceSchedulerCommandOutput extends CreateInferenceSchedulerResponse, __MetadataBearer {
    }
    /**
        * <p> Creates a scheduled inference. Scheduling an inference is setting up a continuous
        *          real-time inference plan to analyze new measurement data. When setting up the schedule, you
        *          provide an S3 bucket location for the input data, assign it a delimiter between separate
        *          entries in the data, set an offset delay if desired, and set the frequency of inferencing.
        *          You must also provide an S3 bucket location for the output data. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, CreateInferenceSchedulerCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, CreateInferenceSchedulerCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new CreateInferenceSchedulerCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link CreateInferenceSchedulerCommandInput} for command's `input` shape.
        * @see {@link CreateInferenceSchedulerCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class CreateInferenceSchedulerCommand extends $Command<CreateInferenceSchedulerCommandInput, CreateInferenceSchedulerCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: CreateInferenceSchedulerCommandInput;
            constructor(input: CreateInferenceSchedulerCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<CreateInferenceSchedulerCommandInput, CreateInferenceSchedulerCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/CreateModelCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { CreateModelRequest, CreateModelResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface CreateModelCommandInput extends CreateModelRequest {
    }
    export interface CreateModelCommandOutput extends CreateModelResponse, __MetadataBearer {
    }
    /**
        * <p>Creates an ML model for data inference. </p>
        *          <p>A machine-learning (ML) model is a mathematical model that finds patterns in your data.
        *          In Amazon Lookout for Equipment, the model learns the patterns of normal behavior and
        *          detects abnormal behavior that could be potential equipment failure (or maintenance
        *          events). The models are made by analyzing normal data and abnormalities in machine behavior
        *          that have already occurred.</p>
        *          <p>Your model is trained using a portion of the data from your dataset and uses that data
        *          to learn patterns of normal behavior and abnormal patterns that lead to equipment failure.
        *          Another portion of the data is used to evaluate the model's accuracy. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, CreateModelCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, CreateModelCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new CreateModelCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link CreateModelCommandInput} for command's `input` shape.
        * @see {@link CreateModelCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class CreateModelCommand extends $Command<CreateModelCommandInput, CreateModelCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: CreateModelCommandInput;
            constructor(input: CreateModelCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<CreateModelCommandInput, CreateModelCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DeleteDatasetCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { DeleteDatasetRequest } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface DeleteDatasetCommandInput extends DeleteDatasetRequest {
    }
    export interface DeleteDatasetCommandOutput extends __MetadataBearer {
    }
    /**
        * <p> Deletes a dataset and associated artifacts. The operation will check to see if any
        *          inference scheduler or data ingestion job is currently using the dataset, and if there
        *          isn't, the dataset, its metadata, and any associated data stored in S3 will be deleted.
        *          This does not affect any models that used this dataset for training and evaluation, but
        *          does prevent it from being used in the future. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, DeleteDatasetCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, DeleteDatasetCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new DeleteDatasetCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link DeleteDatasetCommandInput} for command's `input` shape.
        * @see {@link DeleteDatasetCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class DeleteDatasetCommand extends $Command<DeleteDatasetCommandInput, DeleteDatasetCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: DeleteDatasetCommandInput;
            constructor(input: DeleteDatasetCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<DeleteDatasetCommandInput, DeleteDatasetCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DeleteInferenceSchedulerCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { DeleteInferenceSchedulerRequest } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface DeleteInferenceSchedulerCommandInput extends DeleteInferenceSchedulerRequest {
    }
    export interface DeleteInferenceSchedulerCommandOutput extends __MetadataBearer {
    }
    /**
        * <p>Deletes an inference scheduler that has been set up. Already processed output results
        *          are not affected. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, DeleteInferenceSchedulerCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, DeleteInferenceSchedulerCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new DeleteInferenceSchedulerCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link DeleteInferenceSchedulerCommandInput} for command's `input` shape.
        * @see {@link DeleteInferenceSchedulerCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class DeleteInferenceSchedulerCommand extends $Command<DeleteInferenceSchedulerCommandInput, DeleteInferenceSchedulerCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: DeleteInferenceSchedulerCommandInput;
            constructor(input: DeleteInferenceSchedulerCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<DeleteInferenceSchedulerCommandInput, DeleteInferenceSchedulerCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DeleteModelCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { DeleteModelRequest } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface DeleteModelCommandInput extends DeleteModelRequest {
    }
    export interface DeleteModelCommandOutput extends __MetadataBearer {
    }
    /**
        * <p>Deletes an ML model currently available for Amazon Lookout for Equipment. This will
        *          prevent it from being used with an inference scheduler, even one that is already set up.
        *       </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, DeleteModelCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, DeleteModelCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new DeleteModelCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link DeleteModelCommandInput} for command's `input` shape.
        * @see {@link DeleteModelCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class DeleteModelCommand extends $Command<DeleteModelCommandInput, DeleteModelCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: DeleteModelCommandInput;
            constructor(input: DeleteModelCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<DeleteModelCommandInput, DeleteModelCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DescribeDataIngestionJobCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { DescribeDataIngestionJobRequest, DescribeDataIngestionJobResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface DescribeDataIngestionJobCommandInput extends DescribeDataIngestionJobRequest {
    }
    export interface DescribeDataIngestionJobCommandOutput extends DescribeDataIngestionJobResponse, __MetadataBearer {
    }
    /**
        * <p>Provides information on a specific data ingestion job such as creation time, dataset
        *          ARN, and status.</p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, DescribeDataIngestionJobCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, DescribeDataIngestionJobCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new DescribeDataIngestionJobCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link DescribeDataIngestionJobCommandInput} for command's `input` shape.
        * @see {@link DescribeDataIngestionJobCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class DescribeDataIngestionJobCommand extends $Command<DescribeDataIngestionJobCommandInput, DescribeDataIngestionJobCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: DescribeDataIngestionJobCommandInput;
            constructor(input: DescribeDataIngestionJobCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<DescribeDataIngestionJobCommandInput, DescribeDataIngestionJobCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DescribeDatasetCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { DescribeDatasetRequest, DescribeDatasetResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface DescribeDatasetCommandInput extends DescribeDatasetRequest {
    }
    export interface DescribeDatasetCommandOutput extends DescribeDatasetResponse, __MetadataBearer {
    }
    /**
        * <p>Provides a JSON description of the data in each time series dataset, including names,
        *          column names, and data types.</p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, DescribeDatasetCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, DescribeDatasetCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new DescribeDatasetCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link DescribeDatasetCommandInput} for command's `input` shape.
        * @see {@link DescribeDatasetCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class DescribeDatasetCommand extends $Command<DescribeDatasetCommandInput, DescribeDatasetCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: DescribeDatasetCommandInput;
            constructor(input: DescribeDatasetCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<DescribeDatasetCommandInput, DescribeDatasetCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DescribeInferenceSchedulerCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { DescribeInferenceSchedulerRequest, DescribeInferenceSchedulerResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface DescribeInferenceSchedulerCommandInput extends DescribeInferenceSchedulerRequest {
    }
    export interface DescribeInferenceSchedulerCommandOutput extends DescribeInferenceSchedulerResponse, __MetadataBearer {
    }
    /**
        * <p> Specifies information about the inference scheduler being used, including name, model,
        *          status, and associated metadata </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, DescribeInferenceSchedulerCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, DescribeInferenceSchedulerCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new DescribeInferenceSchedulerCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link DescribeInferenceSchedulerCommandInput} for command's `input` shape.
        * @see {@link DescribeInferenceSchedulerCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class DescribeInferenceSchedulerCommand extends $Command<DescribeInferenceSchedulerCommandInput, DescribeInferenceSchedulerCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: DescribeInferenceSchedulerCommandInput;
            constructor(input: DescribeInferenceSchedulerCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<DescribeInferenceSchedulerCommandInput, DescribeInferenceSchedulerCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DescribeModelCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { DescribeModelRequest, DescribeModelResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface DescribeModelCommandInput extends DescribeModelRequest {
    }
    export interface DescribeModelCommandOutput extends DescribeModelResponse, __MetadataBearer {
    }
    /**
        * <p>Provides a JSON containing the overall information about a specific ML model, including
        *          model name and ARN, dataset, training and evaluation information, status, and so on.
        *       </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, DescribeModelCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, DescribeModelCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new DescribeModelCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link DescribeModelCommandInput} for command's `input` shape.
        * @see {@link DescribeModelCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class DescribeModelCommand extends $Command<DescribeModelCommandInput, DescribeModelCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: DescribeModelCommandInput;
            constructor(input: DescribeModelCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<DescribeModelCommandInput, DescribeModelCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListDataIngestionJobsCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { ListDataIngestionJobsRequest, ListDataIngestionJobsResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface ListDataIngestionJobsCommandInput extends ListDataIngestionJobsRequest {
    }
    export interface ListDataIngestionJobsCommandOutput extends ListDataIngestionJobsResponse, __MetadataBearer {
    }
    /**
        * <p>Provides a list of all data ingestion jobs, including dataset name and ARN, S3 location
        *          of the input data, status, and so on. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, ListDataIngestionJobsCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, ListDataIngestionJobsCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new ListDataIngestionJobsCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link ListDataIngestionJobsCommandInput} for command's `input` shape.
        * @see {@link ListDataIngestionJobsCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class ListDataIngestionJobsCommand extends $Command<ListDataIngestionJobsCommandInput, ListDataIngestionJobsCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: ListDataIngestionJobsCommandInput;
            constructor(input: ListDataIngestionJobsCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<ListDataIngestionJobsCommandInput, ListDataIngestionJobsCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListDatasetsCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { ListDatasetsRequest, ListDatasetsResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface ListDatasetsCommandInput extends ListDatasetsRequest {
    }
    export interface ListDatasetsCommandOutput extends ListDatasetsResponse, __MetadataBearer {
    }
    /**
        * <p>Lists all datasets currently available in your account, filtering on the dataset name.
        *       </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, ListDatasetsCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, ListDatasetsCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new ListDatasetsCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link ListDatasetsCommandInput} for command's `input` shape.
        * @see {@link ListDatasetsCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class ListDatasetsCommand extends $Command<ListDatasetsCommandInput, ListDatasetsCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: ListDatasetsCommandInput;
            constructor(input: ListDatasetsCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<ListDatasetsCommandInput, ListDatasetsCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListInferenceEventsCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { ListInferenceEventsRequest, ListInferenceEventsResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface ListInferenceEventsCommandInput extends ListInferenceEventsRequest {
    }
    export interface ListInferenceEventsCommandOutput extends ListInferenceEventsResponse, __MetadataBearer {
    }
    /**
        * <p> Lists all inference events that have been found for the specified inference
        *          scheduler. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, ListInferenceEventsCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, ListInferenceEventsCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new ListInferenceEventsCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link ListInferenceEventsCommandInput} for command's `input` shape.
        * @see {@link ListInferenceEventsCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class ListInferenceEventsCommand extends $Command<ListInferenceEventsCommandInput, ListInferenceEventsCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: ListInferenceEventsCommandInput;
            constructor(input: ListInferenceEventsCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<ListInferenceEventsCommandInput, ListInferenceEventsCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListInferenceExecutionsCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { ListInferenceExecutionsRequest, ListInferenceExecutionsResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface ListInferenceExecutionsCommandInput extends ListInferenceExecutionsRequest {
    }
    export interface ListInferenceExecutionsCommandOutput extends ListInferenceExecutionsResponse, __MetadataBearer {
    }
    /**
        * <p> Lists all inference executions that have been performed by the specified inference
        *          scheduler. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, ListInferenceExecutionsCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, ListInferenceExecutionsCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new ListInferenceExecutionsCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link ListInferenceExecutionsCommandInput} for command's `input` shape.
        * @see {@link ListInferenceExecutionsCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class ListInferenceExecutionsCommand extends $Command<ListInferenceExecutionsCommandInput, ListInferenceExecutionsCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: ListInferenceExecutionsCommandInput;
            constructor(input: ListInferenceExecutionsCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<ListInferenceExecutionsCommandInput, ListInferenceExecutionsCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListInferenceSchedulersCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { ListInferenceSchedulersRequest, ListInferenceSchedulersResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface ListInferenceSchedulersCommandInput extends ListInferenceSchedulersRequest {
    }
    export interface ListInferenceSchedulersCommandOutput extends ListInferenceSchedulersResponse, __MetadataBearer {
    }
    /**
        * <p>Retrieves a list of all inference schedulers currently available for your account.
        *       </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, ListInferenceSchedulersCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, ListInferenceSchedulersCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new ListInferenceSchedulersCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link ListInferenceSchedulersCommandInput} for command's `input` shape.
        * @see {@link ListInferenceSchedulersCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class ListInferenceSchedulersCommand extends $Command<ListInferenceSchedulersCommandInput, ListInferenceSchedulersCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: ListInferenceSchedulersCommandInput;
            constructor(input: ListInferenceSchedulersCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<ListInferenceSchedulersCommandInput, ListInferenceSchedulersCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListModelsCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { ListModelsRequest, ListModelsResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface ListModelsCommandInput extends ListModelsRequest {
    }
    export interface ListModelsCommandOutput extends ListModelsResponse, __MetadataBearer {
    }
    /**
        * <p>Generates a list of all models in the account, including model name and ARN, dataset,
        *          and status. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, ListModelsCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, ListModelsCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new ListModelsCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link ListModelsCommandInput} for command's `input` shape.
        * @see {@link ListModelsCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class ListModelsCommand extends $Command<ListModelsCommandInput, ListModelsCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: ListModelsCommandInput;
            constructor(input: ListModelsCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<ListModelsCommandInput, ListModelsCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListSensorStatisticsCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { ListSensorStatisticsRequest, ListSensorStatisticsResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface ListSensorStatisticsCommandInput extends ListSensorStatisticsRequest {
    }
    export interface ListSensorStatisticsCommandOutput extends ListSensorStatisticsResponse, __MetadataBearer {
    }
    /**
        * <p> Lists statistics about the data collected for each of the sensors that have been
        *          successfully ingested in the particular dataset. Can also be used to retreive Sensor
        *          Statistics for a previous ingestion job. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, ListSensorStatisticsCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, ListSensorStatisticsCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new ListSensorStatisticsCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link ListSensorStatisticsCommandInput} for command's `input` shape.
        * @see {@link ListSensorStatisticsCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class ListSensorStatisticsCommand extends $Command<ListSensorStatisticsCommandInput, ListSensorStatisticsCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: ListSensorStatisticsCommandInput;
            constructor(input: ListSensorStatisticsCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<ListSensorStatisticsCommandInput, ListSensorStatisticsCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListTagsForResourceCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { ListTagsForResourceRequest, ListTagsForResourceResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface ListTagsForResourceCommandInput extends ListTagsForResourceRequest {
    }
    export interface ListTagsForResourceCommandOutput extends ListTagsForResourceResponse, __MetadataBearer {
    }
    /**
        * <p>Lists all the tags for a specified resource, including key and value. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, ListTagsForResourceCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, ListTagsForResourceCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new ListTagsForResourceCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link ListTagsForResourceCommandInput} for command's `input` shape.
        * @see {@link ListTagsForResourceCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class ListTagsForResourceCommand extends $Command<ListTagsForResourceCommandInput, ListTagsForResourceCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: ListTagsForResourceCommandInput;
            constructor(input: ListTagsForResourceCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<ListTagsForResourceCommandInput, ListTagsForResourceCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/StartDataIngestionJobCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { StartDataIngestionJobRequest, StartDataIngestionJobResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface StartDataIngestionJobCommandInput extends StartDataIngestionJobRequest {
    }
    export interface StartDataIngestionJobCommandOutput extends StartDataIngestionJobResponse, __MetadataBearer {
    }
    /**
        * <p>Starts a data ingestion job. Amazon Lookout for Equipment returns the job status.
        *       </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, StartDataIngestionJobCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, StartDataIngestionJobCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new StartDataIngestionJobCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link StartDataIngestionJobCommandInput} for command's `input` shape.
        * @see {@link StartDataIngestionJobCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class StartDataIngestionJobCommand extends $Command<StartDataIngestionJobCommandInput, StartDataIngestionJobCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: StartDataIngestionJobCommandInput;
            constructor(input: StartDataIngestionJobCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<StartDataIngestionJobCommandInput, StartDataIngestionJobCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/StartInferenceSchedulerCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { StartInferenceSchedulerRequest, StartInferenceSchedulerResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface StartInferenceSchedulerCommandInput extends StartInferenceSchedulerRequest {
    }
    export interface StartInferenceSchedulerCommandOutput extends StartInferenceSchedulerResponse, __MetadataBearer {
    }
    /**
        * <p>Starts an inference scheduler. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, StartInferenceSchedulerCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, StartInferenceSchedulerCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new StartInferenceSchedulerCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link StartInferenceSchedulerCommandInput} for command's `input` shape.
        * @see {@link StartInferenceSchedulerCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class StartInferenceSchedulerCommand extends $Command<StartInferenceSchedulerCommandInput, StartInferenceSchedulerCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: StartInferenceSchedulerCommandInput;
            constructor(input: StartInferenceSchedulerCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<StartInferenceSchedulerCommandInput, StartInferenceSchedulerCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/StopInferenceSchedulerCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { StopInferenceSchedulerRequest, StopInferenceSchedulerResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface StopInferenceSchedulerCommandInput extends StopInferenceSchedulerRequest {
    }
    export interface StopInferenceSchedulerCommandOutput extends StopInferenceSchedulerResponse, __MetadataBearer {
    }
    /**
        * <p>Stops an inference scheduler. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, StopInferenceSchedulerCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, StopInferenceSchedulerCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new StopInferenceSchedulerCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link StopInferenceSchedulerCommandInput} for command's `input` shape.
        * @see {@link StopInferenceSchedulerCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class StopInferenceSchedulerCommand extends $Command<StopInferenceSchedulerCommandInput, StopInferenceSchedulerCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: StopInferenceSchedulerCommandInput;
            constructor(input: StopInferenceSchedulerCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<StopInferenceSchedulerCommandInput, StopInferenceSchedulerCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/TagResourceCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { TagResourceRequest, TagResourceResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface TagResourceCommandInput extends TagResourceRequest {
    }
    export interface TagResourceCommandOutput extends TagResourceResponse, __MetadataBearer {
    }
    /**
        * <p>Associates a given tag to a resource in your account. A tag is a key-value pair which
        *          can be added to an Amazon Lookout for Equipment resource as metadata. Tags can be used for
        *          organizing your resources as well as helping you to search and filter by tag. Multiple tags
        *          can be added to a resource, either when you create it, or later. Up to 50 tags can be
        *          associated with each resource. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, TagResourceCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, TagResourceCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new TagResourceCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link TagResourceCommandInput} for command's `input` shape.
        * @see {@link TagResourceCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class TagResourceCommand extends $Command<TagResourceCommandInput, TagResourceCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: TagResourceCommandInput;
            constructor(input: TagResourceCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<TagResourceCommandInput, TagResourceCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/UntagResourceCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { UntagResourceRequest, UntagResourceResponse } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface UntagResourceCommandInput extends UntagResourceRequest {
    }
    export interface UntagResourceCommandOutput extends UntagResourceResponse, __MetadataBearer {
    }
    /**
        * <p>Removes a specific tag from a given resource. The tag is specified by its key. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, UntagResourceCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, UntagResourceCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new UntagResourceCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link UntagResourceCommandInput} for command's `input` shape.
        * @see {@link UntagResourceCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class UntagResourceCommand extends $Command<UntagResourceCommandInput, UntagResourceCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: UntagResourceCommandInput;
            constructor(input: UntagResourceCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<UntagResourceCommandInput, UntagResourceCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/UpdateInferenceSchedulerCommand' {
    import { Command as $Command } from "@aws-sdk/smithy-client";
    import { Handler, HttpHandlerOptions as __HttpHandlerOptions, MetadataBearer as __MetadataBearer, MiddlewareStack } from "@aws-sdk/types";
    import { LookoutEquipmentClientResolvedConfig, ServiceInputTypes, ServiceOutputTypes } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient";
    import { UpdateInferenceSchedulerRequest } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0";
    export interface UpdateInferenceSchedulerCommandInput extends UpdateInferenceSchedulerRequest {
    }
    export interface UpdateInferenceSchedulerCommandOutput extends __MetadataBearer {
    }
    /**
        * <p>Updates an inference scheduler. </p>
        * @example
        * Use a bare-bones client and the command you need to make an API call.
        * ```javascript
        * import { LookoutEquipmentClient, UpdateInferenceSchedulerCommand } from "@aws-sdk/client-lookoutequipment"; // ES Modules import
        * // const { LookoutEquipmentClient, UpdateInferenceSchedulerCommand } = require("@aws-sdk/client-lookoutequipment"); // CommonJS import
        * const client = new LookoutEquipmentClient(config);
        * const command = new UpdateInferenceSchedulerCommand(input);
        * const response = await client.send(command);
        * ```
        *
        * @see {@link UpdateInferenceSchedulerCommandInput} for command's `input` shape.
        * @see {@link UpdateInferenceSchedulerCommandOutput} for command's `response` shape.
        * @see {@link LookoutEquipmentClientResolvedConfig | config} for LookoutEquipmentClient's `config` shape.
        *
        */
    export class UpdateInferenceSchedulerCommand extends $Command<UpdateInferenceSchedulerCommandInput, UpdateInferenceSchedulerCommandOutput, LookoutEquipmentClientResolvedConfig> {
            readonly input: UpdateInferenceSchedulerCommandInput;
            constructor(input: UpdateInferenceSchedulerCommandInput);
            /**
                * @internal
                */
            resolveMiddleware(clientStack: MiddlewareStack<ServiceInputTypes, ServiceOutputTypes>, configuration: LookoutEquipmentClientResolvedConfig, options?: __HttpHandlerOptions): Handler<UpdateInferenceSchedulerCommandInput, UpdateInferenceSchedulerCommandOutput>;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/LookoutEquipmentClient' {
    import { EndpointsInputConfig, EndpointsResolvedConfig, RegionInputConfig, RegionResolvedConfig } from "@aws-sdk/config-resolver";
    import { HostHeaderInputConfig, HostHeaderResolvedConfig } from "@aws-sdk/middleware-host-header";
    import { RetryInputConfig, RetryResolvedConfig } from "@aws-sdk/middleware-retry";
    import { AwsAuthInputConfig, AwsAuthResolvedConfig } from "@aws-sdk/middleware-signing";
    import { UserAgentInputConfig, UserAgentResolvedConfig } from "@aws-sdk/middleware-user-agent";
    import { HttpHandler as __HttpHandler } from "@aws-sdk/protocol-http";
    import { Client as __Client, DefaultsMode, SmithyConfiguration as __SmithyConfiguration, SmithyResolvedConfiguration as __SmithyResolvedConfiguration } from "@aws-sdk/smithy-client";
    import { BodyLengthCalculator as __BodyLengthCalculator, Credentials as __Credentials, Decoder as __Decoder, Encoder as __Encoder, HashConstructor as __HashConstructor, HttpHandlerOptions as __HttpHandlerOptions, Logger as __Logger, Provider as __Provider, Provider, RegionInfoProvider, StreamCollector as __StreamCollector, UrlParser as __UrlParser, UserAgent as __UserAgent } from "@aws-sdk/types";
    import { CreateDatasetCommandInput, CreateDatasetCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/CreateDatasetCommand";
    import { CreateInferenceSchedulerCommandInput, CreateInferenceSchedulerCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/CreateInferenceSchedulerCommand";
    import { CreateModelCommandInput, CreateModelCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/CreateModelCommand";
    import { DeleteDatasetCommandInput, DeleteDatasetCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DeleteDatasetCommand";
    import { DeleteInferenceSchedulerCommandInput, DeleteInferenceSchedulerCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DeleteInferenceSchedulerCommand";
    import { DeleteModelCommandInput, DeleteModelCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DeleteModelCommand";
    import { DescribeDataIngestionJobCommandInput, DescribeDataIngestionJobCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DescribeDataIngestionJobCommand";
    import { DescribeDatasetCommandInput, DescribeDatasetCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DescribeDatasetCommand";
    import { DescribeInferenceSchedulerCommandInput, DescribeInferenceSchedulerCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DescribeInferenceSchedulerCommand";
    import { DescribeModelCommandInput, DescribeModelCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/DescribeModelCommand";
    import { ListDataIngestionJobsCommandInput, ListDataIngestionJobsCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListDataIngestionJobsCommand";
    import { ListDatasetsCommandInput, ListDatasetsCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListDatasetsCommand";
    import { ListInferenceEventsCommandInput, ListInferenceEventsCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListInferenceEventsCommand";
    import { ListInferenceExecutionsCommandInput, ListInferenceExecutionsCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListInferenceExecutionsCommand";
    import { ListInferenceSchedulersCommandInput, ListInferenceSchedulersCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListInferenceSchedulersCommand";
    import { ListModelsCommandInput, ListModelsCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListModelsCommand";
    import { ListSensorStatisticsCommandInput, ListSensorStatisticsCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListSensorStatisticsCommand";
    import { ListTagsForResourceCommandInput, ListTagsForResourceCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/ListTagsForResourceCommand";
    import { StartDataIngestionJobCommandInput, StartDataIngestionJobCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/StartDataIngestionJobCommand";
    import { StartInferenceSchedulerCommandInput, StartInferenceSchedulerCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/StartInferenceSchedulerCommand";
    import { StopInferenceSchedulerCommandInput, StopInferenceSchedulerCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/StopInferenceSchedulerCommand";
    import { TagResourceCommandInput, TagResourceCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/TagResourceCommand";
    import { UntagResourceCommandInput, UntagResourceCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/UntagResourceCommand";
    import { UpdateInferenceSchedulerCommandInput, UpdateInferenceSchedulerCommandOutput } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/commands/UpdateInferenceSchedulerCommand";
    export type ServiceInputTypes = CreateDatasetCommandInput | CreateInferenceSchedulerCommandInput | CreateModelCommandInput | DeleteDatasetCommandInput | DeleteInferenceSchedulerCommandInput | DeleteModelCommandInput | DescribeDataIngestionJobCommandInput | DescribeDatasetCommandInput | DescribeInferenceSchedulerCommandInput | DescribeModelCommandInput | ListDataIngestionJobsCommandInput | ListDatasetsCommandInput | ListInferenceEventsCommandInput | ListInferenceExecutionsCommandInput | ListInferenceSchedulersCommandInput | ListModelsCommandInput | ListSensorStatisticsCommandInput | ListTagsForResourceCommandInput | StartDataIngestionJobCommandInput | StartInferenceSchedulerCommandInput | StopInferenceSchedulerCommandInput | TagResourceCommandInput | UntagResourceCommandInput | UpdateInferenceSchedulerCommandInput;
    export type ServiceOutputTypes = CreateDatasetCommandOutput | CreateInferenceSchedulerCommandOutput | CreateModelCommandOutput | DeleteDatasetCommandOutput | DeleteInferenceSchedulerCommandOutput | DeleteModelCommandOutput | DescribeDataIngestionJobCommandOutput | DescribeDatasetCommandOutput | DescribeInferenceSchedulerCommandOutput | DescribeModelCommandOutput | ListDataIngestionJobsCommandOutput | ListDatasetsCommandOutput | ListInferenceEventsCommandOutput | ListInferenceExecutionsCommandOutput | ListInferenceSchedulersCommandOutput | ListModelsCommandOutput | ListSensorStatisticsCommandOutput | ListTagsForResourceCommandOutput | StartDataIngestionJobCommandOutput | StartInferenceSchedulerCommandOutput | StopInferenceSchedulerCommandOutput | TagResourceCommandOutput | UntagResourceCommandOutput | UpdateInferenceSchedulerCommandOutput;
    export interface ClientDefaults extends Partial<__SmithyResolvedConfiguration<__HttpHandlerOptions>> {
            /**
                * The HTTP handler to use. Fetch in browser and Https in Nodejs.
                */
            requestHandler?: __HttpHandler;
            /**
                * A constructor for a class implementing the {@link __Hash} interface
                * that computes the SHA-256 HMAC or checksum of a string or binary buffer.
                * @internal
                */
            sha256?: __HashConstructor;
            /**
                * The function that will be used to convert strings into HTTP endpoints.
                * @internal
                */
            urlParser?: __UrlParser;
            /**
                * A function that can calculate the length of a request body.
                * @internal
                */
            bodyLengthChecker?: __BodyLengthCalculator;
            /**
                * A function that converts a stream into an array of bytes.
                * @internal
                */
            streamCollector?: __StreamCollector;
            /**
                * The function that will be used to convert a base64-encoded string to a byte array.
                * @internal
                */
            base64Decoder?: __Decoder;
            /**
                * The function that will be used to convert binary data to a base64-encoded string.
                * @internal
                */
            base64Encoder?: __Encoder;
            /**
                * The function that will be used to convert a UTF8-encoded string to a byte array.
                * @internal
                */
            utf8Decoder?: __Decoder;
            /**
                * The function that will be used to convert binary data to a UTF-8 encoded string.
                * @internal
                */
            utf8Encoder?: __Encoder;
            /**
                * The runtime environment.
                * @internal
                */
            runtime?: string;
            /**
                * Disable dyanamically changing the endpoint of the client based on the hostPrefix
                * trait of an operation.
                */
            disableHostPrefix?: boolean;
            /**
                * Value for how many times a request will be made at most in case of retry.
                */
            maxAttempts?: number | __Provider<number>;
            /**
                * Specifies which retry algorithm to use.
                */
            retryMode?: string | __Provider<string>;
            /**
                * Optional logger for logging debug/info/warn/error.
                */
            logger?: __Logger;
            /**
                * Enables IPv6/IPv4 dualstack endpoint.
                */
            useDualstackEndpoint?: boolean | __Provider<boolean>;
            /**
                * Enables FIPS compatible endpoints.
                */
            useFipsEndpoint?: boolean | __Provider<boolean>;
            /**
                * Unique service identifier.
                * @internal
                */
            serviceId?: string;
            /**
                * The AWS region to which this client will send requests
                */
            region?: string | __Provider<string>;
            /**
                * Default credentials provider; Not available in browser runtime.
                * @internal
                */
            credentialDefaultProvider?: (input: any) => __Provider<__Credentials>;
            /**
                * Fetch related hostname, signing name or signing region with given region.
                * @internal
                */
            regionInfoProvider?: RegionInfoProvider;
            /**
                * The provider populating default tracking information to be sent with `user-agent`, `x-amz-user-agent` header
                * @internal
                */
            defaultUserAgentProvider?: Provider<__UserAgent>;
            /**
                * The {@link DefaultsMode} that will be used to determine how certain default configuration options are resolved in the SDK.
                */
            defaultsMode?: DefaultsMode | Provider<DefaultsMode>;
    }
    type LookoutEquipmentClientConfigType = Partial<__SmithyConfiguration<__HttpHandlerOptions>> & ClientDefaults & RegionInputConfig & EndpointsInputConfig & RetryInputConfig & HostHeaderInputConfig & AwsAuthInputConfig & UserAgentInputConfig;
    /**
        * The configuration interface of LookoutEquipmentClient class constructor that set the region, credentials and other options.
        */
    export interface LookoutEquipmentClientConfig extends LookoutEquipmentClientConfigType {
    }
    type LookoutEquipmentClientResolvedConfigType = __SmithyResolvedConfiguration<__HttpHandlerOptions> & Required<ClientDefaults> & RegionResolvedConfig & EndpointsResolvedConfig & RetryResolvedConfig & HostHeaderResolvedConfig & AwsAuthResolvedConfig & UserAgentResolvedConfig;
    /**
        * The resolved configuration interface of LookoutEquipmentClient class. This is resolved and normalized from the {@link LookoutEquipmentClientConfig | constructor configuration interface}.
        */
    export interface LookoutEquipmentClientResolvedConfig extends LookoutEquipmentClientResolvedConfigType {
    }
    /**
        * <p>Amazon Lookout for Equipment is a machine learning service that uses advanced analytics
        *          to identify anomalies in machines from sensor data for use in predictive maintenance.
        *       </p>
        */
    export class LookoutEquipmentClient extends __Client<__HttpHandlerOptions, ServiceInputTypes, ServiceOutputTypes, LookoutEquipmentClientResolvedConfig> {
            /**
                * The resolved configuration of LookoutEquipmentClient class. This is resolved and normalized from the {@link LookoutEquipmentClientConfig | constructor configuration interface}.
                */
            readonly config: LookoutEquipmentClientResolvedConfig;
            constructor(configuration: LookoutEquipmentClientConfig);
            /**
                * Destroy underlying resources, like sockets. It's usually not necessary to do this.
                * However in Node.js, it's best to explicitly shut down the client's agent when it is no longer needed.
                * Otherwise, sockets might stay open for quite a long time before the server terminates them.
                */
            destroy(): void;
    }
    export {};
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/models_0' {
    import { ExceptionOptionType as __ExceptionOptionType, LazyJsonString as __LazyJsonString } from "@aws-sdk/smithy-client";
    import { LookoutEquipmentServiceException as __BaseException } from "@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/LookoutEquipmentServiceException";
    /**
        * <p>The request could not be completed because you do not have access to the resource.
        *       </p>
        */
    export class AccessDeniedException extends __BaseException {
            readonly name: "AccessDeniedException";
            readonly $fault: "client";
            Message: string | undefined;
            /**
                * @internal
                */
            constructor(opts: __ExceptionOptionType<AccessDeniedException, __BaseException>);
    }
    /**
        * <p> The request could not be completed due to a conflict with the current state of the
        *          target resource. </p>
        */
    export class ConflictException extends __BaseException {
            readonly name: "ConflictException";
            readonly $fault: "client";
            Message: string | undefined;
            /**
                * @internal
                */
            constructor(opts: __ExceptionOptionType<ConflictException, __BaseException>);
    }
    /**
        * <p>Provides information about the data schema used with the given dataset. </p>
        */
    export interface DatasetSchema {
            /**
                * <p>
                *       </p>
                */
            InlineDataSchema?: __LazyJsonString | string;
    }
    export namespace DatasetSchema {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DatasetSchema) => any;
    }
    /**
        * <p>A tag is a key-value pair that can be added to a resource as metadata. </p>
        */
    export interface Tag {
            /**
                * <p>The key for the specified tag. </p>
                */
            Key: string | undefined;
            /**
                * <p>The value for the specified tag. </p>
                */
            Value: string | undefined;
    }
    export namespace Tag {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: Tag) => any;
    }
    export interface CreateDatasetRequest {
            /**
                * <p>The name of the dataset being created. </p>
                */
            DatasetName: string | undefined;
            /**
                * <p>A JSON description of the data that is in each time series dataset, including names,
                *          column names, and data types. </p>
                */
            DatasetSchema?: DatasetSchema;
            /**
                * <p>Provides the identifier of the KMS key used to encrypt dataset data by Amazon Lookout
                *          for Equipment. </p>
                */
            ServerSideKmsKeyId?: string;
            /**
                * <p> A unique identifier for the request. If you do not set the client request token, Amazon
                *          Lookout for Equipment generates one. </p>
                */
            ClientToken?: string;
            /**
                * <p>Any tags associated with the ingested data described in the dataset. </p>
                */
            Tags?: Tag[];
    }
    export namespace CreateDatasetRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: CreateDatasetRequest) => any;
    }
    export enum DatasetStatus {
            ACTIVE = "ACTIVE",
            CREATED = "CREATED",
            INGESTION_IN_PROGRESS = "INGESTION_IN_PROGRESS"
    }
    export interface CreateDatasetResponse {
            /**
                * <p>The name of the dataset being created. </p>
                */
            DatasetName?: string;
            /**
                * <p> The Amazon Resource Name (ARN) of the dataset being created. </p>
                */
            DatasetArn?: string;
            /**
                * <p>Indicates the status of the <code>CreateDataset</code> operation. </p>
                */
            Status?: DatasetStatus | string;
    }
    export namespace CreateDatasetResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: CreateDatasetResponse) => any;
    }
    /**
        * <p> Processing of the request has failed because of an unknown error, exception or failure.
        *       </p>
        */
    export class InternalServerException extends __BaseException {
            readonly name: "InternalServerException";
            readonly $fault: "server";
            Message: string | undefined;
            /**
                * @internal
                */
            constructor(opts: __ExceptionOptionType<InternalServerException, __BaseException>);
    }
    /**
        * <p> Resource limitations have been exceeded. </p>
        */
    export class ServiceQuotaExceededException extends __BaseException {
            readonly name: "ServiceQuotaExceededException";
            readonly $fault: "client";
            Message: string | undefined;
            /**
                * @internal
                */
            constructor(opts: __ExceptionOptionType<ServiceQuotaExceededException, __BaseException>);
    }
    /**
        * <p>The request was denied due to request throttling.</p>
        */
    export class ThrottlingException extends __BaseException {
            readonly name: "ThrottlingException";
            readonly $fault: "client";
            Message: string | undefined;
            /**
                * @internal
                */
            constructor(opts: __ExceptionOptionType<ThrottlingException, __BaseException>);
    }
    /**
        * <p> The input fails to satisfy constraints specified by Amazon Lookout for Equipment or a
        *          related AWS service that's being utilized. </p>
        */
    export class ValidationException extends __BaseException {
            readonly name: "ValidationException";
            readonly $fault: "client";
            Message: string | undefined;
            /**
                * @internal
                */
            constructor(opts: __ExceptionOptionType<ValidationException, __BaseException>);
    }
    /**
        * <p>Specifies configuration information for the input data for the inference, including
        *          timestamp format and delimiter. </p>
        */
    export interface InferenceInputNameConfiguration {
            /**
                * <p>The format of the timestamp, whether Epoch time, or standard, with or without hyphens
                *          (-). </p>
                */
            TimestampFormat?: string;
            /**
                * <p>Indicates the delimiter character used between items in the data. </p>
                */
            ComponentTimestampDelimiter?: string;
    }
    export namespace InferenceInputNameConfiguration {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: InferenceInputNameConfiguration) => any;
    }
    /**
        * <p> Specifies configuration information for the input data for the inference, including
        *          input data S3 location. </p>
        */
    export interface InferenceS3InputConfiguration {
            /**
                * <p>The bucket containing the input dataset for the inference. </p>
                */
            Bucket: string | undefined;
            /**
                * <p>The prefix for the S3 bucket used for the input data for the inference. </p>
                */
            Prefix?: string;
    }
    export namespace InferenceS3InputConfiguration {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: InferenceS3InputConfiguration) => any;
    }
    /**
        * <p>Specifies configuration information for the input data for the inference, including
        *             Amazon S3 location of input data.. </p>
        */
    export interface InferenceInputConfiguration {
            /**
                * <p> Specifies configuration information for the input data for the inference, including
                *             Amazon S3 location of input data.</p>
                */
            S3InputConfiguration?: InferenceS3InputConfiguration;
            /**
                * <p>Indicates the difference between your time zone and Coordinated Universal Time
                *          (UTC).</p>
                */
            InputTimeZoneOffset?: string;
            /**
                * <p>Specifies configuration information for the input data for the inference, including
                *          timestamp format and delimiter. </p>
                */
            InferenceInputNameConfiguration?: InferenceInputNameConfiguration;
    }
    export namespace InferenceInputConfiguration {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: InferenceInputConfiguration) => any;
    }
    /**
        * <p> Specifies configuration information for the output results from the inference,
        *          including output S3 location. </p>
        */
    export interface InferenceS3OutputConfiguration {
            /**
                * <p> The bucket containing the output results from the inference </p>
                */
            Bucket: string | undefined;
            /**
                * <p> The prefix for the S3 bucket used for the output results from the inference. </p>
                */
            Prefix?: string;
    }
    export namespace InferenceS3OutputConfiguration {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: InferenceS3OutputConfiguration) => any;
    }
    /**
        * <p> Specifies configuration information for the output results from for the inference,
        *          including KMS key ID and output S3 location. </p>
        */
    export interface InferenceOutputConfiguration {
            /**
                * <p> Specifies configuration information for the output results from for the inference,
                *          output S3 location. </p>
                */
            S3OutputConfiguration: InferenceS3OutputConfiguration | undefined;
            /**
                * <p>The ID number for the AWS KMS key used to encrypt the inference output. </p>
                */
            KmsKeyId?: string;
    }
    export namespace InferenceOutputConfiguration {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: InferenceOutputConfiguration) => any;
    }
    export enum DataUploadFrequency {
            PT10M = "PT10M",
            PT15M = "PT15M",
            PT1H = "PT1H",
            PT30M = "PT30M",
            PT5M = "PT5M"
    }
    export interface CreateInferenceSchedulerRequest {
            /**
                * <p>The name of the previously trained ML model being used to create the inference
                *          scheduler. </p>
                */
            ModelName: string | undefined;
            /**
                * <p>The name of the inference scheduler being created. </p>
                */
            InferenceSchedulerName: string | undefined;
            /**
                * <p>A period of time (in minutes) by which inference on the data is delayed after the data
                *          starts. For instance, if you select an offset delay time of five minutes, inference will
                *          not begin on the data until the first data measurement after the five minute mark. For
                *          example, if five minutes is selected, the inference scheduler will wake up at the
                *          configured frequency with the additional five minute delay time to check the customer S3
                *          bucket. The customer can upload data at the same frequency and they don't need to stop and
                *          restart the scheduler when uploading new data. </p>
                */
            DataDelayOffsetInMinutes?: number;
            /**
                * <p> How often data is uploaded to the source S3 bucket for the input data. The value chosen
                *          is the length of time between data uploads. For instance, if you select 5 minutes, Amazon
                *          Lookout for Equipment will upload the real-time data to the source bucket once every 5
                *          minutes. This frequency also determines how often Amazon Lookout for Equipment starts a
                *          scheduled inference on your data. In this example, it starts once every 5 minutes. </p>
                */
            DataUploadFrequency: DataUploadFrequency | string | undefined;
            /**
                * <p>Specifies configuration information for the input data for the inference scheduler,
                *          including delimiter, format, and dataset location. </p>
                */
            DataInputConfiguration: InferenceInputConfiguration | undefined;
            /**
                * <p>Specifies configuration information for the output results for the inference scheduler,
                *          including the S3 location for the output. </p>
                */
            DataOutputConfiguration: InferenceOutputConfiguration | undefined;
            /**
                * <p>The Amazon Resource Name (ARN) of a role with permission to access the data source being
                *          used for the inference. </p>
                */
            RoleArn: string | undefined;
            /**
                * <p>Provides the identifier of the KMS key used to encrypt inference scheduler data by
                *          Amazon Lookout for Equipment. </p>
                */
            ServerSideKmsKeyId?: string;
            /**
                * <p> A unique identifier for the request. If you do not set the client request token, Amazon
                *          Lookout for Equipment generates one. </p>
                */
            ClientToken?: string;
            /**
                * <p>Any tags associated with the inference scheduler. </p>
                */
            Tags?: Tag[];
    }
    export namespace CreateInferenceSchedulerRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: CreateInferenceSchedulerRequest) => any;
    }
    export enum InferenceSchedulerStatus {
            PENDING = "PENDING",
            RUNNING = "RUNNING",
            STOPPED = "STOPPED",
            STOPPING = "STOPPING"
    }
    export interface CreateInferenceSchedulerResponse {
            /**
                * <p>The Amazon Resource Name (ARN) of the inference scheduler being created. </p>
                */
            InferenceSchedulerArn?: string;
            /**
                * <p>The name of inference scheduler being created. </p>
                */
            InferenceSchedulerName?: string;
            /**
                * <p>Indicates the status of the <code>CreateInferenceScheduler</code> operation. </p>
                */
            Status?: InferenceSchedulerStatus | string;
    }
    export namespace CreateInferenceSchedulerResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: CreateInferenceSchedulerResponse) => any;
    }
    /**
        * <p> The resource requested could not be found. Verify the resource ID and retry your
        *          request. </p>
        */
    export class ResourceNotFoundException extends __BaseException {
            readonly name: "ResourceNotFoundException";
            readonly $fault: "client";
            Message: string | undefined;
            /**
                * @internal
                */
            constructor(opts: __ExceptionOptionType<ResourceNotFoundException, __BaseException>);
    }
    export enum TargetSamplingRate {
            PT10M = "PT10M",
            PT10S = "PT10S",
            PT15M = "PT15M",
            PT15S = "PT15S",
            PT1H = "PT1H",
            PT1M = "PT1M",
            PT1S = "PT1S",
            PT30M = "PT30M",
            PT30S = "PT30S",
            PT5M = "PT5M",
            PT5S = "PT5S"
    }
    /**
        * <p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of
        *          the data after post processing by Amazon Lookout for Equipment. For example, if you provide
        *          data that has been collected at a 1 second level and you want the system to resample the
        *          data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1
        *          minute.</p>
        *          <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the
        *          prefix "PT" to the rate you want. The value for a 1 second rate is therefore
        *             <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>,
        *          and the value for a 1 hour rate is <i>PT1H</i>
        *          </p>
        */
    export interface DataPreProcessingConfiguration {
            /**
                * <p>The sampling rate of the data after post processing by Amazon Lookout for Equipment. For
                *          example, if you provide data that has been collected at a 1 second level and you want the
                *          system to resample the data at a 1 minute rate before training, the
                *             <code>TargetSamplingRate</code> is 1 minute.</p>
                *          <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the
                *          prefix "PT" to the rate you want. The value for a 1 second rate is therefore
                *             <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>,
                *          and the value for a 1 hour rate is <i>PT1H</i>
                *          </p>
                */
            TargetSamplingRate?: TargetSamplingRate | string;
    }
    export namespace DataPreProcessingConfiguration {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DataPreProcessingConfiguration) => any;
    }
    /**
        * <p>The location information (prefix and bucket name) for the s3 location being used for
        *          label data. </p>
        */
    export interface LabelsS3InputConfiguration {
            /**
                * <p>The name of the S3 bucket holding the label data. </p>
                */
            Bucket: string | undefined;
            /**
                * <p> The prefix for the S3 bucket used for the label data. </p>
                */
            Prefix?: string;
    }
    export namespace LabelsS3InputConfiguration {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: LabelsS3InputConfiguration) => any;
    }
    /**
        * <p>Contains the configuration information for the S3 location being used to hold label
        *          data. </p>
        */
    export interface LabelsInputConfiguration {
            /**
                * <p>Contains location information for the S3 location being used for label data. </p>
                */
            S3InputConfiguration: LabelsS3InputConfiguration | undefined;
    }
    export namespace LabelsInputConfiguration {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: LabelsInputConfiguration) => any;
    }
    export interface CreateModelRequest {
            /**
                * <p>The name for the ML model to be created.</p>
                */
            ModelName: string | undefined;
            /**
                * <p>The name of the dataset for the ML model being created. </p>
                */
            DatasetName: string | undefined;
            /**
                * <p>The data schema for the ML model being created. </p>
                */
            DatasetSchema?: DatasetSchema;
            /**
                * <p>The input configuration for the labels being used for the ML model that's being created.
                *       </p>
                */
            LabelsInputConfiguration?: LabelsInputConfiguration;
            /**
                * <p>A unique identifier for the request. If you do not set the client request token, Amazon
                *          Lookout for Equipment generates one. </p>
                */
            ClientToken?: string;
            /**
                * <p>Indicates the time reference in the dataset that should be used to begin the subset of
                *          training data for the ML model. </p>
                */
            TrainingDataStartTime?: Date;
            /**
                * <p>Indicates the time reference in the dataset that should be used to end the subset of
                *          training data for the ML model. </p>
                */
            TrainingDataEndTime?: Date;
            /**
                * <p>Indicates the time reference in the dataset that should be used to begin the subset of
                *          evaluation data for the ML model. </p>
                */
            EvaluationDataStartTime?: Date;
            /**
                * <p> Indicates the time reference in the dataset that should be used to end the subset of
                *          evaluation data for the ML model. </p>
                */
            EvaluationDataEndTime?: Date;
            /**
                * <p> The Amazon Resource Name (ARN) of a role with permission to access the data source
                *          being used to create the ML model. </p>
                */
            RoleArn?: string;
            /**
                * <p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of
                *          the data after post processing by Amazon Lookout for Equipment. For example, if you provide
                *          data that has been collected at a 1 second level and you want the system to resample the
                *          data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1
                *          minute.</p>
                *          <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the
                *          prefix "PT" to the rate you want. The value for a 1 second rate is therefore
                *             <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>,
                *          and the value for a 1 hour rate is <i>PT1H</i>
                *          </p>
                */
            DataPreProcessingConfiguration?: DataPreProcessingConfiguration;
            /**
                * <p>Provides the identifier of the KMS key used to encrypt model data by Amazon Lookout
                *          for Equipment. </p>
                */
            ServerSideKmsKeyId?: string;
            /**
                * <p> Any tags associated with the ML model being created. </p>
                */
            Tags?: Tag[];
            /**
                * <p>Indicates that the asset associated with this sensor has been shut off. As long as this
                *          condition is met, Lookout for Equipment will not use data from this asset for training,
                *          evaluation, or inference.</p>
                */
            OffCondition?: string;
    }
    export namespace CreateModelRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: CreateModelRequest) => any;
    }
    export enum ModelStatus {
            FAILED = "FAILED",
            IN_PROGRESS = "IN_PROGRESS",
            SUCCESS = "SUCCESS"
    }
    export interface CreateModelResponse {
            /**
                * <p>The Amazon Resource Name (ARN) of the model being created. </p>
                */
            ModelArn?: string;
            /**
                * <p>Indicates the status of the <code>CreateModel</code> operation. </p>
                */
            Status?: ModelStatus | string;
    }
    export namespace CreateModelResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: CreateModelResponse) => any;
    }
    export interface DeleteDatasetRequest {
            /**
                * <p>The name of the dataset to be deleted. </p>
                */
            DatasetName: string | undefined;
    }
    export namespace DeleteDatasetRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DeleteDatasetRequest) => any;
    }
    export interface DeleteInferenceSchedulerRequest {
            /**
                * <p>The name of the inference scheduler to be deleted. </p>
                */
            InferenceSchedulerName: string | undefined;
    }
    export namespace DeleteInferenceSchedulerRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DeleteInferenceSchedulerRequest) => any;
    }
    export interface DeleteModelRequest {
            /**
                * <p>The name of the ML model to be deleted. </p>
                */
            ModelName: string | undefined;
    }
    export namespace DeleteModelRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DeleteModelRequest) => any;
    }
    export interface DescribeDataIngestionJobRequest {
            /**
                * <p>The job ID of the data ingestion job. </p>
                */
            JobId: string | undefined;
    }
    export namespace DescribeDataIngestionJobRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DescribeDataIngestionJobRequest) => any;
    }
    /**
        * <p> Entity that comprises information abount duplicate timestamps in the dataset. </p>
        */
    export interface DuplicateTimestamps {
            /**
                * <p> Indicates the total number of duplicate timestamps. </p>
                */
            TotalNumberOfDuplicateTimestamps: number | undefined;
    }
    export namespace DuplicateTimestamps {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DuplicateTimestamps) => any;
    }
    /**
        * <p> Entity that comprises information on sensors that have sensor data completely missing.
        *       </p>
        */
    export interface MissingCompleteSensorData {
            /**
                * <p> Indicates the number of sensors that have data missing completely. </p>
                */
            AffectedSensorCount: number | undefined;
    }
    export namespace MissingCompleteSensorData {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: MissingCompleteSensorData) => any;
    }
    /**
        * <p> Entity that comprises information on sensors that have shorter date range. </p>
        */
    export interface SensorsWithShortDateRange {
            /**
                * <p> Indicates the number of sensors that have less than 90 days of data. </p>
                */
            AffectedSensorCount: number | undefined;
    }
    export namespace SensorsWithShortDateRange {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: SensorsWithShortDateRange) => any;
    }
    /**
        * <p> Entity that comprises aggregated information on sensors having insufficient data.
        *       </p>
        */
    export interface InsufficientSensorData {
            /**
                * <p> Parameter that describes the total number of sensors that have data completely missing
                *          for it. </p>
                */
            MissingCompleteSensorData: MissingCompleteSensorData | undefined;
            /**
                * <p> Parameter that describes the total number of sensors that have a short date range of
                *          less than 90 days of data overall. </p>
                */
            SensorsWithShortDateRange: SensorsWithShortDateRange | undefined;
    }
    export namespace InsufficientSensorData {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: InsufficientSensorData) => any;
    }
    /**
        * <p> Entity that comprises aggregated information on sensors having insufficient data.
        *       </p>
        */
    export interface InvalidSensorData {
            /**
                * <p> Indicates the number of sensors that have at least some invalid values. </p>
                */
            AffectedSensorCount: number | undefined;
            /**
                * <p> Indicates the total number of invalid values across all the sensors. </p>
                */
            TotalNumberOfInvalidValues: number | undefined;
    }
    export namespace InvalidSensorData {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: InvalidSensorData) => any;
    }
    /**
        * <p> Entity that comprises aggregated information on sensors having missing data. </p>
        */
    export interface MissingSensorData {
            /**
                * <p> Indicates the number of sensors that have atleast some data missing. </p>
                */
            AffectedSensorCount: number | undefined;
            /**
                * <p> Indicates the total number of missing values across all the sensors. </p>
                */
            TotalNumberOfMissingValues: number | undefined;
    }
    export namespace MissingSensorData {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: MissingSensorData) => any;
    }
    /**
        * <p> Entity that comprises information abount unsupported timestamps in the dataset. </p>
        */
    export interface UnsupportedTimestamps {
            /**
                * <p> Indicates the total number of unsupported timestamps across the ingested data. </p>
                */
            TotalNumberOfUnsupportedTimestamps: number | undefined;
    }
    export namespace UnsupportedTimestamps {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: UnsupportedTimestamps) => any;
    }
    /**
        * <p> DataQualitySummary gives aggregated statistics over all the sensors about a completed
        *          ingestion job. It primarily gives more information about statistics over different
        *          incorrect data like MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats,
        *          InsufficientSensorData, DuplicateTimeStamps. </p>
        */
    export interface DataQualitySummary {
            /**
                * <p> Parameter that gives information about insufficient data for sensors in the dataset.
                *          This includes information about those sensors that have complete data missing and those
                *          with a short date range. </p>
                */
            InsufficientSensorData: InsufficientSensorData | undefined;
            /**
                * <p> Parameter that gives information about data that is missing over all the sensors in the
                *          input data. </p>
                */
            MissingSensorData: MissingSensorData | undefined;
            /**
                * <p> Parameter that gives information about data that is invalid over all the sensors in the
                *          input data. </p>
                */
            InvalidSensorData: InvalidSensorData | undefined;
            /**
                * <p> Parameter that gives information about unsupported timestamps in the input data.
                *       </p>
                */
            UnsupportedTimestamps: UnsupportedTimestamps | undefined;
            /**
                * <p> Parameter that gives information about duplicate timestamps in the input data. </p>
                */
            DuplicateTimestamps: DuplicateTimestamps | undefined;
    }
    export namespace DataQualitySummary {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DataQualitySummary) => any;
    }
    /**
        * <p>Contains information about an S3 bucket. </p>
        */
    export interface S3Object {
            /**
                * <p>The name of the specific S3 bucket. </p>
                */
            Bucket: string | undefined;
            /**
                * <p>The AWS Key Management Service (AWS KMS) key being used to encrypt the S3 object.
                *          Without this key, data in the bucket is not accessible. </p>
                */
            Key: string | undefined;
    }
    export namespace S3Object {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: S3Object) => any;
    }
    /**
        * <p>Gives statistics about how many files have been ingested, and which files have not been
        *          ingested, for a particular ingestion job.</p>
        */
    export interface IngestedFilesSummary {
            /**
                * <p>Indicates the total number of files that were submitted for ingestion.</p>
                */
            TotalNumberOfFiles: number | undefined;
            /**
                * <p>Indicates the number of files that were successfully ingested.</p>
                */
            IngestedNumberOfFiles: number | undefined;
            /**
                * <p>Indicates the number of files that were discarded. A file could be discarded because its
                *          format is invalid (for example, a jpg or pdf) or not readable.</p>
                */
            DiscardedFiles?: S3Object[];
    }
    export namespace IngestedFilesSummary {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: IngestedFilesSummary) => any;
    }
    /**
        * <p> Specifies S3 configuration information for the input data for the data ingestion job.
        *       </p>
        */
    export interface IngestionS3InputConfiguration {
            /**
                * <p>The name of the S3 bucket used for the input data for the data ingestion. </p>
                */
            Bucket: string | undefined;
            /**
                * <p>The prefix for the S3 location being used for the input data for the data ingestion.
                *       </p>
                */
            Prefix?: string;
            /**
                * <p> Pattern for matching the Amazon S3 files which will be used for ingestion. If
                *          no KeyPattern is provided, we will use the default hierarchy file structure, which is same
                *          as KeyPattern {prefix}/{component_name}/* </p>
                */
            KeyPattern?: string;
    }
    export namespace IngestionS3InputConfiguration {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: IngestionS3InputConfiguration) => any;
    }
    /**
        * <p> Specifies configuration information for the input data for the data ingestion job,
        *          including input data S3 location. </p>
        */
    export interface IngestionInputConfiguration {
            /**
                * <p>The location information for the S3 bucket used for input data for the data ingestion.
                *       </p>
                */
            S3InputConfiguration: IngestionS3InputConfiguration | undefined;
    }
    export namespace IngestionInputConfiguration {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: IngestionInputConfiguration) => any;
    }
    export enum IngestionJobStatus {
            FAILED = "FAILED",
            IN_PROGRESS = "IN_PROGRESS",
            SUCCESS = "SUCCESS"
    }
    export interface DescribeDataIngestionJobResponse {
            /**
                * <p>Indicates the job ID of the data ingestion job. </p>
                */
            JobId?: string;
            /**
                * <p>The Amazon Resource Name (ARN) of the dataset being used in the data ingestion job.
                *       </p>
                */
            DatasetArn?: string;
            /**
                * <p>Specifies the S3 location configuration for the data input for the data ingestion job.
                *       </p>
                */
            IngestionInputConfiguration?: IngestionInputConfiguration;
            /**
                * <p>The Amazon Resource Name (ARN) of an IAM role with permission to access the data source
                *          being ingested. </p>
                */
            RoleArn?: string;
            /**
                * <p>The time at which the data ingestion job was created. </p>
                */
            CreatedAt?: Date;
            /**
                * <p>Indicates the status of the <code>DataIngestionJob</code> operation. </p>
                */
            Status?: IngestionJobStatus | string;
            /**
                * <p>Specifies the reason for failure when a data ingestion job has failed. </p>
                */
            FailedReason?: string;
            /**
                * <p> Gives statistics about a completed ingestion job. These statistics primarily relate to
                *          quantifying incorrect data such as MissingCompleteSensorData, MissingSensorData,
                *          UnsupportedDateFormats, InsufficientSensorData, and DuplicateTimeStamps. </p>
                */
            DataQualitySummary?: DataQualitySummary;
            /**
                * <p>Gives statistics about how many files have been ingested, and which files have not been
                *          ingested, for a particular ingestion job.</p>
                */
            IngestedFilesSummary?: IngestedFilesSummary;
            /**
                * <p>
                *          Provides details about status of the ingestion job that is currently in progress.
                *       </p>
                */
            StatusDetail?: string;
            /**
                * <p>
                *          Indicates the size of the ingested dataset.
                *       </p>
                */
            IngestedDataSize?: number;
            /**
                * <p>
                *          Indicates the earliest timestamp corresponding to data that was successfully ingested during this specific ingestion job.
                *       </p>
                */
            DataStartTime?: Date;
            /**
                * <p>
                *          Indicates the latest timestamp corresponding to data that was successfully ingested during this specific ingestion job.
                *       </p>
                */
            DataEndTime?: Date;
    }
    export namespace DescribeDataIngestionJobResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DescribeDataIngestionJobResponse) => any;
    }
    export interface DescribeDatasetRequest {
            /**
                * <p>The name of the dataset to be described. </p>
                */
            DatasetName: string | undefined;
    }
    export namespace DescribeDatasetRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DescribeDatasetRequest) => any;
    }
    export interface DescribeDatasetResponse {
            /**
                * <p>The name of the dataset being described. </p>
                */
            DatasetName?: string;
            /**
                * <p>The Amazon Resource Name (ARN) of the dataset being described. </p>
                */
            DatasetArn?: string;
            /**
                * <p>Specifies the time the dataset was created in Lookout for Equipment. </p>
                */
            CreatedAt?: Date;
            /**
                * <p>Specifies the time the dataset was last updated, if it was. </p>
                */
            LastUpdatedAt?: Date;
            /**
                * <p>Indicates the status of the dataset. </p>
                */
            Status?: DatasetStatus | string;
            /**
                * <p>A JSON description of the data that is in each time series dataset, including names,
                *          column names, and data types. </p>
                */
            Schema?: __LazyJsonString | string;
            /**
                * <p>Provides the identifier of the KMS key used to encrypt dataset data by Amazon Lookout
                *          for Equipment. </p>
                */
            ServerSideKmsKeyId?: string;
            /**
                * <p>Specifies the S3 location configuration for the data input for the data ingestion job.
                *       </p>
                */
            IngestionInputConfiguration?: IngestionInputConfiguration;
            /**
                * <p> Gives statistics associated with the given dataset for the latest successful associated
                *          ingestion job id. These statistics primarily relate to quantifying incorrect data such as
                *          MissingCompleteSensorData, MissingSensorData, UnsupportedDateFormats,
                *          InsufficientSensorData, and DuplicateTimeStamps. </p>
                */
            DataQualitySummary?: DataQualitySummary;
            /**
                * <p> IngestedFilesSummary associated with the given dataset for the latest successful
                *          associated ingestion job id. </p>
                */
            IngestedFilesSummary?: IngestedFilesSummary;
            /**
                * <p>
                *          The Amazon Resource Name (ARN) of the IAM role that you are using for this the data ingestion job.
                *       </p>
                */
            RoleArn?: string;
            /**
                * <p>
                *          Indicates the earliest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset.
                *       </p>
                */
            DataStartTime?: Date;
            /**
                * <p>
                *          Indicates the latest timestamp corresponding to data that was successfully ingested during the most recent ingestion of this particular dataset.
                *       </p>
                */
            DataEndTime?: Date;
    }
    export namespace DescribeDatasetResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DescribeDatasetResponse) => any;
    }
    export interface DescribeInferenceSchedulerRequest {
            /**
                * <p>The name of the inference scheduler being described. </p>
                */
            InferenceSchedulerName: string | undefined;
    }
    export namespace DescribeInferenceSchedulerRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DescribeInferenceSchedulerRequest) => any;
    }
    export interface DescribeInferenceSchedulerResponse {
            /**
                * <p>The Amazon Resource Name (ARN) of the ML model of the inference scheduler being
                *          described. </p>
                */
            ModelArn?: string;
            /**
                * <p>The name of the ML model of the inference scheduler being described. </p>
                */
            ModelName?: string;
            /**
                * <p>The name of the inference scheduler being described. </p>
                */
            InferenceSchedulerName?: string;
            /**
                * <p>The Amazon Resource Name (ARN) of the inference scheduler being described. </p>
                */
            InferenceSchedulerArn?: string;
            /**
                * <p>Indicates the status of the inference scheduler. </p>
                */
            Status?: InferenceSchedulerStatus | string;
            /**
                * <p> A period of time (in minutes) by which inference on the data is delayed after the data
                *          starts. For instance, if you select an offset delay time of five minutes, inference will
                *          not begin on the data until the first data measurement after the five minute mark. For
                *          example, if five minutes is selected, the inference scheduler will wake up at the
                *          configured frequency with the additional five minute delay time to check the customer S3
                *          bucket. The customer can upload data at the same frequency and they don't need to stop and
                *          restart the scheduler when uploading new data.</p>
                */
            DataDelayOffsetInMinutes?: number;
            /**
                * <p>Specifies how often data is uploaded to the source S3 bucket for the input data. This
                *          value is the length of time between data uploads. For instance, if you select 5 minutes,
                *          Amazon Lookout for Equipment will upload the real-time data to the source bucket once every
                *          5 minutes. This frequency also determines how often Amazon Lookout for Equipment starts a
                *          scheduled inference on your data. In this example, it starts once every 5 minutes. </p>
                */
            DataUploadFrequency?: DataUploadFrequency | string;
            /**
                * <p>Specifies the time at which the inference scheduler was created. </p>
                */
            CreatedAt?: Date;
            /**
                * <p>Specifies the time at which the inference scheduler was last updated, if it was. </p>
                */
            UpdatedAt?: Date;
            /**
                * <p> Specifies configuration information for the input data for the inference scheduler,
                *          including delimiter, format, and dataset location. </p>
                */
            DataInputConfiguration?: InferenceInputConfiguration;
            /**
                * <p> Specifies information for the output results for the inference scheduler, including
                *          the output S3 location. </p>
                */
            DataOutputConfiguration?: InferenceOutputConfiguration;
            /**
                * <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for
                *          the inference scheduler being described. </p>
                */
            RoleArn?: string;
            /**
                * <p>Provides the identifier of the KMS key used to encrypt inference scheduler data by
                *          Amazon Lookout for Equipment. </p>
                */
            ServerSideKmsKeyId?: string;
    }
    export namespace DescribeInferenceSchedulerResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DescribeInferenceSchedulerResponse) => any;
    }
    export interface DescribeModelRequest {
            /**
                * <p>The name of the ML model to be described. </p>
                */
            ModelName: string | undefined;
    }
    export namespace DescribeModelRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DescribeModelRequest) => any;
    }
    export interface DescribeModelResponse {
            /**
                * <p>The name of the ML model being described. </p>
                */
            ModelName?: string;
            /**
                * <p>The Amazon Resource Name (ARN) of the ML model being described. </p>
                */
            ModelArn?: string;
            /**
                * <p>The name of the dataset being used by the ML being described. </p>
                */
            DatasetName?: string;
            /**
                * <p>The Amazon Resouce Name (ARN) of the dataset used to create the ML model being
                *          described. </p>
                */
            DatasetArn?: string;
            /**
                * <p>A JSON description of the data that is in each time series dataset, including names,
                *          column names, and data types. </p>
                */
            Schema?: __LazyJsonString | string;
            /**
                * <p>Specifies configuration information about the labels input, including its S3 location.
                *       </p>
                */
            LabelsInputConfiguration?: LabelsInputConfiguration;
            /**
                * <p> Indicates the time reference in the dataset that was used to begin the subset of
                *          training data for the ML model. </p>
                */
            TrainingDataStartTime?: Date;
            /**
                * <p> Indicates the time reference in the dataset that was used to end the subset of training
                *          data for the ML model. </p>
                */
            TrainingDataEndTime?: Date;
            /**
                * <p> Indicates the time reference in the dataset that was used to begin the subset of
                *          evaluation data for the ML model. </p>
                */
            EvaluationDataStartTime?: Date;
            /**
                * <p> Indicates the time reference in the dataset that was used to end the subset of
                *          evaluation data for the ML model. </p>
                */
            EvaluationDataEndTime?: Date;
            /**
                * <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for
                *          the ML model being described. </p>
                */
            RoleArn?: string;
            /**
                * <p>The configuration is the <code>TargetSamplingRate</code>, which is the sampling rate of
                *          the data after post processing by Amazon Lookout for Equipment. For example, if you provide
                *          data that has been collected at a 1 second level and you want the system to resample the
                *          data at a 1 minute rate before training, the <code>TargetSamplingRate</code> is 1
                *          minute.</p>
                *          <p>When providing a value for the <code>TargetSamplingRate</code>, you must attach the
                *          prefix "PT" to the rate you want. The value for a 1 second rate is therefore
                *             <i>PT1S</i>, the value for a 15 minute rate is <i>PT15M</i>,
                *          and the value for a 1 hour rate is <i>PT1H</i>
                *          </p>
                */
            DataPreProcessingConfiguration?: DataPreProcessingConfiguration;
            /**
                * <p>Specifies the current status of the model being described. Status describes the status
                *          of the most recent action of the model. </p>
                */
            Status?: ModelStatus | string;
            /**
                * <p>Indicates the time at which the training of the ML model began. </p>
                */
            TrainingExecutionStartTime?: Date;
            /**
                * <p>Indicates the time at which the training of the ML model was completed. </p>
                */
            TrainingExecutionEndTime?: Date;
            /**
                * <p>If the training of the ML model failed, this indicates the reason for that failure.
                *       </p>
                */
            FailedReason?: string;
            /**
                * <p>The Model Metrics show an aggregated summary of the model's performance within the
                *          evaluation time range. This is the JSON content of the metrics created when evaluating the
                *          model. </p>
                */
            ModelMetrics?: __LazyJsonString | string;
            /**
                * <p>Indicates the last time the ML model was updated. The type of update is not specified.
                *       </p>
                */
            LastUpdatedTime?: Date;
            /**
                * <p>Indicates the time and date at which the ML model was created. </p>
                */
            CreatedAt?: Date;
            /**
                * <p>Provides the identifier of the KMS key used to encrypt model data by Amazon Lookout
                *          for Equipment. </p>
                */
            ServerSideKmsKeyId?: string;
            /**
                * <p>Indicates that the asset associated with this sensor has been shut off. As long as this
                *          condition is met, Lookout for Equipment will not use data from this asset for training,
                *          evaluation, or inference.</p>
                */
            OffCondition?: string;
    }
    export namespace DescribeModelResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DescribeModelResponse) => any;
    }
    export interface ListDataIngestionJobsRequest {
            /**
                * <p>The name of the dataset being used for the data ingestion job. </p>
                */
            DatasetName?: string;
            /**
                * <p> An opaque pagination token indicating where to continue the listing of data ingestion
                *          jobs. </p>
                */
            NextToken?: string;
            /**
                * <p> Specifies the maximum number of data ingestion jobs to list. </p>
                */
            MaxResults?: number;
            /**
                * <p>Indicates the status of the data ingestion job. </p>
                */
            Status?: IngestionJobStatus | string;
    }
    export namespace ListDataIngestionJobsRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListDataIngestionJobsRequest) => any;
    }
    /**
        * <p>Provides information about a specified data ingestion job, including dataset
        *          information, data ingestion configuration, and status. </p>
        */
    export interface DataIngestionJobSummary {
            /**
                * <p>Indicates the job ID of the data ingestion job. </p>
                */
            JobId?: string;
            /**
                * <p>The name of the dataset used for the data ingestion job. </p>
                */
            DatasetName?: string;
            /**
                * <p>The Amazon Resource Name (ARN) of the dataset used in the data ingestion job. </p>
                */
            DatasetArn?: string;
            /**
                * <p> Specifies information for the input data for the data inference job, including data
                *             Amazon S3 location parameters. </p>
                */
            IngestionInputConfiguration?: IngestionInputConfiguration;
            /**
                * <p>Indicates the status of the data ingestion job. </p>
                */
            Status?: IngestionJobStatus | string;
    }
    export namespace DataIngestionJobSummary {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DataIngestionJobSummary) => any;
    }
    export interface ListDataIngestionJobsResponse {
            /**
                * <p> An opaque pagination token indicating where to continue the listing of data ingestion
                *          jobs. </p>
                */
            NextToken?: string;
            /**
                * <p>Specifies information about the specific data ingestion job, including dataset name and
                *          status. </p>
                */
            DataIngestionJobSummaries?: DataIngestionJobSummary[];
    }
    export namespace ListDataIngestionJobsResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListDataIngestionJobsResponse) => any;
    }
    export interface ListDatasetsRequest {
            /**
                * <p> An opaque pagination token indicating where to continue the listing of datasets.
                *       </p>
                */
            NextToken?: string;
            /**
                * <p> Specifies the maximum number of datasets to list. </p>
                */
            MaxResults?: number;
            /**
                * <p>The beginning of the name of the datasets to be listed. </p>
                */
            DatasetNameBeginsWith?: string;
    }
    export namespace ListDatasetsRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListDatasetsRequest) => any;
    }
    /**
        * <p>Contains information about the specific data set, including name, ARN, and status.
        *       </p>
        */
    export interface DatasetSummary {
            /**
                * <p>The name of the dataset. </p>
                */
            DatasetName?: string;
            /**
                * <p>The Amazon Resource Name (ARN) of the specified dataset. </p>
                */
            DatasetArn?: string;
            /**
                * <p>Indicates the status of the dataset. </p>
                */
            Status?: DatasetStatus | string;
            /**
                * <p>The time at which the dataset was created in Amazon Lookout for Equipment. </p>
                */
            CreatedAt?: Date;
    }
    export namespace DatasetSummary {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: DatasetSummary) => any;
    }
    export interface ListDatasetsResponse {
            /**
                * <p> An opaque pagination token indicating where to continue the listing of datasets.
                *       </p>
                */
            NextToken?: string;
            /**
                * <p>Provides information about the specified dataset, including creation time, dataset ARN,
                *          and status. </p>
                */
            DatasetSummaries?: DatasetSummary[];
    }
    export namespace ListDatasetsResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListDatasetsResponse) => any;
    }
    export interface ListInferenceEventsRequest {
            /**
                * <p>An opaque pagination token indicating where to continue the listing of inference
                *          events.</p>
                */
            NextToken?: string;
            /**
                * <p>Specifies the maximum number of inference events to list. </p>
                */
            MaxResults?: number;
            /**
                * <p>The name of the inference scheduler for the inference events listed. </p>
                */
            InferenceSchedulerName: string | undefined;
            /**
                * <p> Lookout for Equipment will return all the inference events with start time equal to or greater than the start time given.</p>
                */
            IntervalStartTime: Date | undefined;
            /**
                * <p>Lookout for Equipment will return all the inference events with end time equal to or less than the end time given.</p>
                */
            IntervalEndTime: Date | undefined;
    }
    export namespace ListInferenceEventsRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListInferenceEventsRequest) => any;
    }
    /**
        * <p>Contains information about the specific inference event, including start and end time,
        *          diagnostics information, event duration and so on.</p>
        */
    export interface InferenceEventSummary {
            /**
                * <p> The Amazon Resource Name (ARN) of the inference scheduler being used for the inference
                *          event. </p>
                */
            InferenceSchedulerArn?: string;
            /**
                * <p>The name of the inference scheduler being used for the inference events. </p>
                */
            InferenceSchedulerName?: string;
            /**
                * <p>Indicates the starting time of an inference event.
                *       </p>
                */
            EventStartTime?: Date;
            /**
                * <p>Indicates the ending time of an inference event.
                *       </p>
                */
            EventEndTime?: Date;
            /**
                * <p> An array which specifies the names and values of all sensors contributing to an inference event.</p>
                */
            Diagnostics?: string;
            /**
                * <p> Indicates the size of an inference event in seconds.
                *       </p>
                */
            EventDurationInSeconds?: number;
    }
    export namespace InferenceEventSummary {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: InferenceEventSummary) => any;
    }
    export interface ListInferenceEventsResponse {
            /**
                * <p>An opaque pagination token indicating where to continue the listing of inference
                *          executions. </p>
                */
            NextToken?: string;
            /**
                * <p>Provides an array of information about the individual inference events returned from
                *          the <code>ListInferenceEvents</code> operation, including scheduler used, event start time,
                *          event end time, diagnostics, and so on. </p>
                */
            InferenceEventSummaries?: InferenceEventSummary[];
    }
    export namespace ListInferenceEventsResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListInferenceEventsResponse) => any;
    }
    export enum InferenceExecutionStatus {
            FAILED = "FAILED",
            IN_PROGRESS = "IN_PROGRESS",
            SUCCESS = "SUCCESS"
    }
    export interface ListInferenceExecutionsRequest {
            /**
                * <p>An opaque pagination token indicating where to continue the listing of inference
                *          executions.</p>
                */
            NextToken?: string;
            /**
                * <p>Specifies the maximum number of inference executions to list. </p>
                */
            MaxResults?: number;
            /**
                * <p>The name of the inference scheduler for the inference execution listed. </p>
                */
            InferenceSchedulerName: string | undefined;
            /**
                * <p>The time reference in the inferenced dataset after which Amazon Lookout for Equipment
                *          started the inference execution. </p>
                */
            DataStartTimeAfter?: Date;
            /**
                * <p>The time reference in the inferenced dataset before which Amazon Lookout for Equipment
                *          stopped the inference execution. </p>
                */
            DataEndTimeBefore?: Date;
            /**
                * <p>The status of the inference execution. </p>
                */
            Status?: InferenceExecutionStatus | string;
    }
    export namespace ListInferenceExecutionsRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListInferenceExecutionsRequest) => any;
    }
    /**
        * <p>Contains information about the specific inference execution, including input and output
        *          data configuration, inference scheduling information, status, and so on. </p>
        */
    export interface InferenceExecutionSummary {
            /**
                * <p>The name of the ML model being used for the inference execution. </p>
                */
            ModelName?: string;
            /**
                * <p>The Amazon Resource Name (ARN) of the ML model used for the inference execution. </p>
                */
            ModelArn?: string;
            /**
                * <p>The name of the inference scheduler being used for the inference execution. </p>
                */
            InferenceSchedulerName?: string;
            /**
                * <p> The Amazon Resource Name (ARN) of the inference scheduler being used for the inference
                *          execution. </p>
                */
            InferenceSchedulerArn?: string;
            /**
                * <p>Indicates the start time at which the inference scheduler began the specific inference
                *          execution. </p>
                */
            ScheduledStartTime?: Date;
            /**
                * <p>Indicates the time reference in the dataset at which the inference execution began.
                *       </p>
                */
            DataStartTime?: Date;
            /**
                * <p>Indicates the time reference in the dataset at which the inference execution stopped.
                *       </p>
                */
            DataEndTime?: Date;
            /**
                * <p> Specifies configuration information for the input data for the inference scheduler,
                *          including delimiter, format, and dataset location. </p>
                */
            DataInputConfiguration?: InferenceInputConfiguration;
            /**
                * <p> Specifies configuration information for the output results from for the inference
                *          execution, including the output Amazon S3 location.
                *       </p>
                */
            DataOutputConfiguration?: InferenceOutputConfiguration;
            /**
                * <p>
                *       </p>
                */
            CustomerResultObject?: S3Object;
            /**
                * <p>Indicates the status of the inference execution. </p>
                */
            Status?: InferenceExecutionStatus | string;
            /**
                * <p> Specifies the reason for failure when an inference execution has failed. </p>
                */
            FailedReason?: string;
    }
    export namespace InferenceExecutionSummary {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: InferenceExecutionSummary) => any;
    }
    export interface ListInferenceExecutionsResponse {
            /**
                * <p> An opaque pagination token indicating where to continue the listing of inference
                *          executions. </p>
                */
            NextToken?: string;
            /**
                * <p>Provides an array of information about the individual inference executions returned from
                *          the <code>ListInferenceExecutions</code> operation, including model used, inference
                *          scheduler, data configuration, and so on. </p>
                */
            InferenceExecutionSummaries?: InferenceExecutionSummary[];
    }
    export namespace ListInferenceExecutionsResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListInferenceExecutionsResponse) => any;
    }
    export interface ListInferenceSchedulersRequest {
            /**
                * <p> An opaque pagination token indicating where to continue the listing of inference
                *          schedulers. </p>
                */
            NextToken?: string;
            /**
                * <p> Specifies the maximum number of inference schedulers to list. </p>
                */
            MaxResults?: number;
            /**
                * <p>The beginning of the name of the inference schedulers to be listed. </p>
                */
            InferenceSchedulerNameBeginsWith?: string;
            /**
                * <p>The name of the ML model used by the inference scheduler to be listed. </p>
                */
            ModelName?: string;
    }
    export namespace ListInferenceSchedulersRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListInferenceSchedulersRequest) => any;
    }
    /**
        * <p>Contains information about the specific inference scheduler, including data delay
        *          offset, model name and ARN, status, and so on. </p>
        */
    export interface InferenceSchedulerSummary {
            /**
                * <p>The name of the ML model used for the inference scheduler. </p>
                */
            ModelName?: string;
            /**
                * <p> The Amazon Resource Name (ARN) of the ML model used by the inference scheduler. </p>
                */
            ModelArn?: string;
            /**
                * <p>The name of the inference scheduler. </p>
                */
            InferenceSchedulerName?: string;
            /**
                * <p> The Amazon Resource Name (ARN) of the inference scheduler. </p>
                */
            InferenceSchedulerArn?: string;
            /**
                * <p>Indicates the status of the inference scheduler. </p>
                */
            Status?: InferenceSchedulerStatus | string;
            /**
                * <p>A period of time (in minutes) by which inference on the data is delayed after the data
                *          starts. For instance, if an offset delay time of five minutes was selected, inference will
                *          not begin on the data until the first data measurement after the five minute mark. For
                *          example, if five minutes is selected, the inference scheduler will wake up at the
                *          configured frequency with the additional five minute delay time to check the customer S3
                *          bucket. The customer can upload data at the same frequency and they don't need to stop and
                *          restart the scheduler when uploading new data. </p>
                */
            DataDelayOffsetInMinutes?: number;
            /**
                * <p>How often data is uploaded to the source S3 bucket for the input data. This value is the
                *          length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout
                *          for Equipment will upload the real-time data to the source bucket once every 5 minutes.
                *          This frequency also determines how often Amazon Lookout for Equipment starts a scheduled
                *          inference on your data. In this example, it starts once every 5 minutes. </p>
                */
            DataUploadFrequency?: DataUploadFrequency | string;
    }
    export namespace InferenceSchedulerSummary {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: InferenceSchedulerSummary) => any;
    }
    export interface ListInferenceSchedulersResponse {
            /**
                * <p> An opaque pagination token indicating where to continue the listing of inference
                *          schedulers. </p>
                */
            NextToken?: string;
            /**
                * <p>Provides information about the specified inference scheduler, including data upload
                *          frequency, model name and ARN, and status. </p>
                */
            InferenceSchedulerSummaries?: InferenceSchedulerSummary[];
    }
    export namespace ListInferenceSchedulersResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListInferenceSchedulersResponse) => any;
    }
    export interface ListModelsRequest {
            /**
                * <p> An opaque pagination token indicating where to continue the listing of ML models.
                *       </p>
                */
            NextToken?: string;
            /**
                * <p> Specifies the maximum number of ML models to list. </p>
                */
            MaxResults?: number;
            /**
                * <p>The status of the ML model. </p>
                */
            Status?: ModelStatus | string;
            /**
                * <p>The beginning of the name of the ML models being listed. </p>
                */
            ModelNameBeginsWith?: string;
            /**
                * <p>The beginning of the name of the dataset of the ML models to be listed. </p>
                */
            DatasetNameBeginsWith?: string;
    }
    export namespace ListModelsRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListModelsRequest) => any;
    }
    /**
        * <p>Provides information about the specified ML model, including dataset and model names and
        *          ARNs, as well as status. </p>
        */
    export interface ModelSummary {
            /**
                * <p>The name of the ML model. </p>
                */
            ModelName?: string;
            /**
                * <p> The Amazon Resource Name (ARN) of the ML model. </p>
                */
            ModelArn?: string;
            /**
                * <p>The name of the dataset being used for the ML model. </p>
                */
            DatasetName?: string;
            /**
                * <p> The Amazon Resource Name (ARN) of the dataset used to create the model. </p>
                */
            DatasetArn?: string;
            /**
                * <p>Indicates the status of the ML model. </p>
                */
            Status?: ModelStatus | string;
            /**
                * <p>The time at which the specific model was created. </p>
                */
            CreatedAt?: Date;
    }
    export namespace ModelSummary {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ModelSummary) => any;
    }
    export interface ListModelsResponse {
            /**
                * <p> An opaque pagination token indicating where to continue the listing of ML models.
                *       </p>
                */
            NextToken?: string;
            /**
                * <p>Provides information on the specified model, including created time, model and dataset
                *          ARNs, and status. </p>
                */
            ModelSummaries?: ModelSummary[];
    }
    export namespace ListModelsResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListModelsResponse) => any;
    }
    export interface ListSensorStatisticsRequest {
            /**
                * <p> The name of the dataset associated with the list of Sensor Statistics. </p>
                */
            DatasetName: string | undefined;
            /**
                * <p> The ingestion job id associated with the list of Sensor Statistics. To get sensor
                *          statistics for a particular ingestion job id, both dataset name and ingestion job id must
                *          be submitted as inputs. </p>
                */
            IngestionJobId?: string;
            /**
                * <p> Specifies the maximum number of sensors for which to retrieve statistics. </p>
                */
            MaxResults?: number;
            /**
                * <p> An opaque pagination token indicating where to continue the listing of sensor
                *          statistics. </p>
                */
            NextToken?: string;
    }
    export namespace ListSensorStatisticsRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListSensorStatisticsRequest) => any;
    }
    export enum StatisticalIssueStatus {
            NO_ISSUE_DETECTED = "NO_ISSUE_DETECTED",
            POTENTIAL_ISSUE_DETECTED = "POTENTIAL_ISSUE_DETECTED"
    }
    /**
        * <p> Entity that comprises information on categorical values in data. </p>
        */
    export interface CategoricalValues {
            /**
                * <p> Indicates whether there is a potential data issue related to categorical values.
                *       </p>
                */
            Status: StatisticalIssueStatus | string | undefined;
            /**
                * <p> Indicates the number of categories in the data. </p>
                */
            NumberOfCategory?: number;
    }
    export namespace CategoricalValues {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: CategoricalValues) => any;
    }
    /**
        * <p> Entity that comprises information of count and percentage. </p>
        */
    export interface CountPercent {
            /**
                * <p> Indicates the count of occurences of the given statistic. </p>
                */
            Count: number | undefined;
            /**
                * <p> Indicates the percentage of occurances of the given statistic. </p>
                */
            Percentage: number | undefined;
    }
    export namespace CountPercent {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: CountPercent) => any;
    }
    /**
        * <p> Entity that comprises information on large gaps between consecutive timestamps in data.
        *       </p>
        */
    export interface LargeTimestampGaps {
            /**
                * <p> Indicates whether there is a potential data issue related to large gaps in timestamps.
                *       </p>
                */
            Status: StatisticalIssueStatus | string | undefined;
            /**
                * <p> Indicates the number of large timestamp gaps, if there are any. </p>
                */
            NumberOfLargeTimestampGaps?: number;
            /**
                * <p> Indicates the size of the largest timestamp gap, in days. </p>
                */
            MaxTimestampGapInDays?: number;
    }
    export namespace LargeTimestampGaps {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: LargeTimestampGaps) => any;
    }
    export enum Monotonicity {
            DECREASING = "DECREASING",
            INCREASING = "INCREASING",
            STATIC = "STATIC"
    }
    /**
        * <p> Entity that comprises information on monotonic values in the data. </p>
        */
    export interface MonotonicValues {
            /**
                * <p> Indicates whether there is a potential data issue related to having monotonic values.
                *       </p>
                */
            Status: StatisticalIssueStatus | string | undefined;
            /**
                * <p> Indicates the monotonicity of values. Can be INCREASING, DECREASING, or STATIC. </p>
                */
            Monotonicity?: Monotonicity | string;
    }
    export namespace MonotonicValues {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: MonotonicValues) => any;
    }
    /**
        * <p> Entity that comprises information on operating modes in data. </p>
        */
    export interface MultipleOperatingModes {
            /**
                * <p> Indicates whether there is a potential data issue related to having multiple operating
                *          modes. </p>
                */
            Status: StatisticalIssueStatus | string | undefined;
    }
    export namespace MultipleOperatingModes {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: MultipleOperatingModes) => any;
    }
    /**
        * <p> Summary of ingestion statistics like whether data exists, number of missing values,
        *          number of invalid values and so on related to the particular sensor. </p>
        */
    export interface SensorStatisticsSummary {
            /**
                * <p> Name of the component to which the particular sensor belongs for which the statistics
                *          belong to. </p>
                */
            ComponentName?: string;
            /**
                * <p> Name of the sensor that the statistics belong to. </p>
                */
            SensorName?: string;
            /**
                * <p> Parameter that indicates whether data exists for the sensor that the statistics belong
                *          to. </p>
                */
            DataExists?: boolean;
            /**
                * <p> Parameter that describes the total number of, and percentage of, values that are
                *          missing for the sensor that the statistics belong to. </p>
                */
            MissingValues?: CountPercent;
            /**
                * <p> Parameter that describes the total number of, and percentage of, values that are
                *          invalid for the sensor that the statistics belong to. </p>
                */
            InvalidValues?: CountPercent;
            /**
                * <p> Parameter that describes the total number of invalid date entries associated with the
                *          sensor that the statistics belong to. </p>
                */
            InvalidDateEntries?: CountPercent;
            /**
                * <p> Parameter that describes the total number of duplicate timestamp records associated
                *          with the sensor that the statistics belong to. </p>
                */
            DuplicateTimestamps?: CountPercent;
            /**
                * <p> Parameter that describes potential risk about whether data associated with the sensor
                *          is categorical. </p>
                */
            CategoricalValues?: CategoricalValues;
            /**
                * <p> Parameter that describes potential risk about whether data associated with the sensor
                *          has more than one operating mode. </p>
                */
            MultipleOperatingModes?: MultipleOperatingModes;
            /**
                * <p> Parameter that describes potential risk about whether data associated with the sensor
                *          contains one or more large gaps between consecutive timestamps. </p>
                */
            LargeTimestampGaps?: LargeTimestampGaps;
            /**
                * <p> Parameter that describes potential risk about whether data associated with the sensor
                *          is mostly monotonic. </p>
                */
            MonotonicValues?: MonotonicValues;
            /**
                * <p> Indicates the time reference to indicate the beginning of valid data associated with
                *          the sensor that the statistics belong to. </p>
                */
            DataStartTime?: Date;
            /**
                * <p> Indicates the time reference to indicate the end of valid data associated with the
                *          sensor that the statistics belong to. </p>
                */
            DataEndTime?: Date;
    }
    export namespace SensorStatisticsSummary {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: SensorStatisticsSummary) => any;
    }
    export interface ListSensorStatisticsResponse {
            /**
                * <p> Provides ingestion-based statistics regarding the specified sensor with respect to
                *          various validation types, such as whether data exists, the number and percentage of missing
                *          values, and the number and percentage of duplicate timestamps. </p>
                */
            SensorStatisticsSummaries?: SensorStatisticsSummary[];
            /**
                * <p> An opaque pagination token indicating where to continue the listing of sensor
                *          statistics. </p>
                */
            NextToken?: string;
    }
    export namespace ListSensorStatisticsResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListSensorStatisticsResponse) => any;
    }
    export interface ListTagsForResourceRequest {
            /**
                * <p>The Amazon Resource Name (ARN) of the resource (such as the dataset or model) that is
                *          the focus of the <code>ListTagsForResource</code> operation. </p>
                */
            ResourceArn: string | undefined;
    }
    export namespace ListTagsForResourceRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListTagsForResourceRequest) => any;
    }
    export interface ListTagsForResourceResponse {
            /**
                * <p> Any tags associated with the resource. </p>
                */
            Tags?: Tag[];
    }
    export namespace ListTagsForResourceResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: ListTagsForResourceResponse) => any;
    }
    export interface StartDataIngestionJobRequest {
            /**
                * <p>The name of the dataset being used by the data ingestion job. </p>
                */
            DatasetName: string | undefined;
            /**
                * <p> Specifies information for the input data for the data ingestion job, including dataset
                *          S3 location. </p>
                */
            IngestionInputConfiguration: IngestionInputConfiguration | undefined;
            /**
                * <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for
                *          the data ingestion job. </p>
                */
            RoleArn: string | undefined;
            /**
                * <p> A unique identifier for the request. If you do not set the client request token, Amazon
                *          Lookout for Equipment generates one. </p>
                */
            ClientToken?: string;
    }
    export namespace StartDataIngestionJobRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: StartDataIngestionJobRequest) => any;
    }
    export interface StartDataIngestionJobResponse {
            /**
                * <p>Indicates the job ID of the data ingestion job. </p>
                */
            JobId?: string;
            /**
                * <p>Indicates the status of the <code>StartDataIngestionJob</code> operation. </p>
                */
            Status?: IngestionJobStatus | string;
    }
    export namespace StartDataIngestionJobResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: StartDataIngestionJobResponse) => any;
    }
    export interface StartInferenceSchedulerRequest {
            /**
                * <p>The name of the inference scheduler to be started. </p>
                */
            InferenceSchedulerName: string | undefined;
    }
    export namespace StartInferenceSchedulerRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: StartInferenceSchedulerRequest) => any;
    }
    export interface StartInferenceSchedulerResponse {
            /**
                * <p>The Amazon Resource Name (ARN) of the ML model being used by the inference scheduler.
                *       </p>
                */
            ModelArn?: string;
            /**
                * <p>The name of the ML model being used by the inference scheduler. </p>
                */
            ModelName?: string;
            /**
                * <p>The name of the inference scheduler being started. </p>
                */
            InferenceSchedulerName?: string;
            /**
                * <p>The Amazon Resource Name (ARN) of the inference scheduler being started. </p>
                */
            InferenceSchedulerArn?: string;
            /**
                * <p>Indicates the status of the inference scheduler. </p>
                */
            Status?: InferenceSchedulerStatus | string;
    }
    export namespace StartInferenceSchedulerResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: StartInferenceSchedulerResponse) => any;
    }
    export interface StopInferenceSchedulerRequest {
            /**
                * <p>The name of the inference scheduler to be stopped. </p>
                */
            InferenceSchedulerName: string | undefined;
    }
    export namespace StopInferenceSchedulerRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: StopInferenceSchedulerRequest) => any;
    }
    export interface StopInferenceSchedulerResponse {
            /**
                * <p>The Amazon Resource Name (ARN) of the ML model used by the inference scheduler being
                *          stopped. </p>
                */
            ModelArn?: string;
            /**
                * <p>The name of the ML model used by the inference scheduler being stopped. </p>
                */
            ModelName?: string;
            /**
                * <p>The name of the inference scheduler being stopped. </p>
                */
            InferenceSchedulerName?: string;
            /**
                * <p>The Amazon Resource Name (ARN) of the inference schedule being stopped. </p>
                */
            InferenceSchedulerArn?: string;
            /**
                * <p>Indicates the status of the inference scheduler. </p>
                */
            Status?: InferenceSchedulerStatus | string;
    }
    export namespace StopInferenceSchedulerResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: StopInferenceSchedulerResponse) => any;
    }
    export interface TagResourceRequest {
            /**
                * <p>The Amazon Resource Name (ARN) of the specific resource to which the tag should be
                *          associated. </p>
                */
            ResourceArn: string | undefined;
            /**
                * <p>The tag or tags to be associated with a specific resource. Both the tag key and value
                *          are specified. </p>
                */
            Tags: Tag[] | undefined;
    }
    export namespace TagResourceRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: TagResourceRequest) => any;
    }
    export interface TagResourceResponse {
    }
    export namespace TagResourceResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: TagResourceResponse) => any;
    }
    export interface UntagResourceRequest {
            /**
                * <p>The Amazon Resource Name (ARN) of the resource to which the tag is currently associated.
                *       </p>
                */
            ResourceArn: string | undefined;
            /**
                * <p>Specifies the key of the tag to be removed from a specified resource. </p>
                */
            TagKeys: string[] | undefined;
    }
    export namespace UntagResourceRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: UntagResourceRequest) => any;
    }
    export interface UntagResourceResponse {
    }
    export namespace UntagResourceResponse {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: UntagResourceResponse) => any;
    }
    export interface UpdateInferenceSchedulerRequest {
            /**
                * <p>The name of the inference scheduler to be updated. </p>
                */
            InferenceSchedulerName: string | undefined;
            /**
                * <p> A period of time (in minutes) by which inference on the data is delayed after the data
                *          starts. For instance, if you select an offset delay time of five minutes, inference will
                *          not begin on the data until the first data measurement after the five minute mark. For
                *          example, if five minutes is selected, the inference scheduler will wake up at the
                *          configured frequency with the additional five minute delay time to check the customer S3
                *          bucket. The customer can upload data at the same frequency and they don't need to stop and
                *          restart the scheduler when uploading new data.</p>
                */
            DataDelayOffsetInMinutes?: number;
            /**
                * <p>How often data is uploaded to the source S3 bucket for the input data. The value chosen
                *          is the length of time between data uploads. For instance, if you select 5 minutes, Amazon
                *          Lookout for Equipment will upload the real-time data to the source bucket once every 5
                *          minutes. This frequency also determines how often Amazon Lookout for Equipment starts a
                *          scheduled inference on your data. In this example, it starts once every 5 minutes. </p>
                */
            DataUploadFrequency?: DataUploadFrequency | string;
            /**
                * <p> Specifies information for the input data for the inference scheduler, including
                *          delimiter, format, and dataset location. </p>
                */
            DataInputConfiguration?: InferenceInputConfiguration;
            /**
                * <p> Specifies information for the output results from the inference scheduler, including
                *          the output S3 location. </p>
                */
            DataOutputConfiguration?: InferenceOutputConfiguration;
            /**
                * <p> The Amazon Resource Name (ARN) of a role with permission to access the data source for
                *          the inference scheduler. </p>
                */
            RoleArn?: string;
    }
    export namespace UpdateInferenceSchedulerRequest {
            /**
                * @internal
                */
            const filterSensitiveLog: (obj: UpdateInferenceSchedulerRequest) => any;
    }
}

declare module '@aws-sdk/client-lookoutequipment/node_modules/@aws-sdk/client-lookoutequipment/dist-types/models/LookoutEquipmentServiceException' {
    import { ServiceException as __ServiceException, ServiceExceptionOptions as __ServiceExceptionOptions } from "@aws-sdk/smithy-client";
    /**
        * Base exception class for all service exceptions from LookoutEquipment service.
        */
    export class LookoutEquipmentServiceException extends __ServiceException {
            /**
                * @internal
                */
            constructor(options: __ServiceExceptionOptions);
    }
}

